/* Karatsuba multiplication mod M*/

inline void force_inline mul512_8_2078K_modM(__m512i out[80], __m512i a512[40], __m512i b512[40])
{

	// D0 = Al*Bl

	__m512i D0_0, D0_1;
	__m512i D0_2, D0_3;
	__m512i D0_4, D0_5;
	__m512i D0_6, D0_7;
	__m512i D0_8, D0_9;
	__m512i D0_10, D0_11;
	__m512i D0_12, D0_13;
	__m512i D0_14, D0_15;
	__m512i D0_16, D0_17;
	__m512i D0_18, D0_19;
	__m512i D0_20, D0_21;
	__m512i D0_22, D0_23;
	__m512i D0_24, D0_25;
	__m512i D0_26, D0_27;
	__m512i D0_28, D0_29;
	__m512i D0_30, D0_31;
	__m512i D0_32, D0_33;
	__m512i D0_34, D0_35;
	__m512i D0_36, D0_37;
	__m512i D0_38, D0_39;
	__m512i a5120 = _mm512_load_epi64(a512), b5120 = _mm512_load_epi64(b512);
	__m512i a5121 = _mm512_load_epi64(a512+1), b5121 = _mm512_load_epi64(b512+1);
	__m512i a5122 = _mm512_load_epi64(a512+2), b5122 = _mm512_load_epi64(b512+2);
	__m512i a5123 = _mm512_load_epi64(a512+3), b5123 = _mm512_load_epi64(b512+3);
	__m512i a5124 = _mm512_load_epi64(a512+4), b5124 = _mm512_load_epi64(b512+4);
	__m512i a5125 = _mm512_load_epi64(a512+5), b5125 = _mm512_load_epi64(b512+5);
	__m512i a5126 = _mm512_load_epi64(a512+6), b5126 = _mm512_load_epi64(b512+6);
	__m512i a5127 = _mm512_load_epi64(a512+7), b5127 = _mm512_load_epi64(b512+7);
	__m512i a5128 = _mm512_load_epi64(a512+8), b5128 = _mm512_load_epi64(b512+8);
	__m512i a5129 = _mm512_load_epi64(a512+9), b5129 = _mm512_load_epi64(b512+9);
	__m512i a51210 = _mm512_load_epi64(a512+10), b51210 = _mm512_load_epi64(b512+10);
	__m512i a51211 = _mm512_load_epi64(a512+11), b51211 = _mm512_load_epi64(b512+11);
	__m512i a51212 = _mm512_load_epi64(a512+12), b51212 = _mm512_load_epi64(b512+12);
	__m512i a51213 = _mm512_load_epi64(a512+13), b51213 = _mm512_load_epi64(b512+13);
	__m512i a51214 = _mm512_load_epi64(a512+14), b51214 = _mm512_load_epi64(b512+14);
	__m512i a51215 = _mm512_load_epi64(a512+15), b51215 = _mm512_load_epi64(b512+15);
	__m512i a51216 = _mm512_load_epi64(a512+16), b51216 = _mm512_load_epi64(b512+16);
	__m512i a51217 = _mm512_load_epi64(a512+17), b51217 = _mm512_load_epi64(b512+17);
	__m512i a51218 = _mm512_load_epi64(a512+18), b51218 = _mm512_load_epi64(b512+18);
	__m512i a51219 = _mm512_load_epi64(a512+19), b51219 = _mm512_load_epi64(b512+19);
	D0_0 = _mm512_madd52lo_epu64(zero,a5120,b5120);
	D0_1 = _mm512_madd52hi_epu64(zero,a5120,b5120);
	D0_1 = _mm512_madd52lo_epu64(D0_1,a5120,b5121);
	D0_2 = _mm512_madd52hi_epu64(zero,a5120,b5121);
	D0_2 = _mm512_madd52lo_epu64(D0_2,a5120,b5122);
	D0_3 = _mm512_madd52hi_epu64(zero,a5120,b5122);
	D0_3 = _mm512_madd52lo_epu64(D0_3,a5120,b5123);
	D0_4 = _mm512_madd52hi_epu64(zero,a5120,b5123);
	D0_4 = _mm512_madd52lo_epu64(D0_4,a5120,b5124);
	D0_5 = _mm512_madd52hi_epu64(zero,a5120,b5124);
	D0_5 = _mm512_madd52lo_epu64(D0_5,a5120,b5125);
	D0_6 = _mm512_madd52hi_epu64(zero,a5120,b5125);
	D0_6 = _mm512_madd52lo_epu64(D0_6,a5120,b5126);
	D0_7 = _mm512_madd52hi_epu64(zero,a5120,b5126);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5120,b5127);
	D0_8 = _mm512_madd52hi_epu64(zero,a5120,b5127);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5120,b5128);
	D0_9 = _mm512_madd52hi_epu64(zero,a5120,b5128);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5120,b5129);
	D0_10 = _mm512_madd52hi_epu64(zero,a5120,b5129);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5120,b51210);
	D0_11 = _mm512_madd52hi_epu64(zero,a5120,b51210);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5120,b51211);
	D0_12 = _mm512_madd52hi_epu64(zero,a5120,b51211);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5120,b51212);
	D0_13 = _mm512_madd52hi_epu64(zero,a5120,b51212);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5120,b51213);
	D0_14 = _mm512_madd52hi_epu64(zero,a5120,b51213);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5120,b51214);
	D0_15 = _mm512_madd52hi_epu64(zero,a5120,b51214);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5120,b51215);
	D0_16 = _mm512_madd52hi_epu64(zero,a5120,b51215);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5120,b51216);
	D0_17 = _mm512_madd52hi_epu64(zero,a5120,b51216);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5120,b51217);
	D0_18 = _mm512_madd52hi_epu64(zero,a5120,b51217);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5120,b51218);
	D0_19 = _mm512_madd52hi_epu64(zero,a5120,b51218);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5120,b51219);
	D0_20 = _mm512_madd52hi_epu64(zero,a5120,b51219);

	D0_1 = _mm512_madd52lo_epu64(D0_1,a5121,b5120);
	D0_2 = _mm512_madd52hi_epu64(D0_2,a5121,b5120);
	D0_2 = _mm512_madd52lo_epu64(D0_2,a5121,b5121);
	D0_3 = _mm512_madd52hi_epu64(D0_3,a5121,b5121);
	D0_3 = _mm512_madd52lo_epu64(D0_3,a5121,b5122);
	D0_4 = _mm512_madd52hi_epu64(D0_4,a5121,b5122);
	D0_4 = _mm512_madd52lo_epu64(D0_4,a5121,b5123);
	D0_5 = _mm512_madd52hi_epu64(D0_5,a5121,b5123);
	D0_5 = _mm512_madd52lo_epu64(D0_5,a5121,b5124);
	D0_6 = _mm512_madd52hi_epu64(D0_6,a5121,b5124);
	D0_6 = _mm512_madd52lo_epu64(D0_6,a5121,b5125);
	D0_7 = _mm512_madd52hi_epu64(D0_7,a5121,b5125);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5121,b5126);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5121,b5126);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5121,b5127);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5121,b5127);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5121,b5128);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5121,b5128);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5121,b5129);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5121,b5129);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5121,b51210);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5121,b51210);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5121,b51211);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5121,b51211);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5121,b51212);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5121,b51212);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5121,b51213);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5121,b51213);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5121,b51214);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5121,b51214);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5121,b51215);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5121,b51215);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5121,b51216);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5121,b51216);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5121,b51217);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5121,b51217);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5121,b51218);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5121,b51218);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5121,b51219);
	D0_21 = _mm512_madd52hi_epu64(zero,a5121,b51219);

	D0_2 = _mm512_madd52lo_epu64(D0_2,a5122,b5120);
	D0_3 = _mm512_madd52hi_epu64(D0_3,a5122,b5120);
	D0_3 = _mm512_madd52lo_epu64(D0_3,a5122,b5121);
	D0_4 = _mm512_madd52hi_epu64(D0_4,a5122,b5121);
	D0_4 = _mm512_madd52lo_epu64(D0_4,a5122,b5122);
	D0_5 = _mm512_madd52hi_epu64(D0_5,a5122,b5122);
	D0_5 = _mm512_madd52lo_epu64(D0_5,a5122,b5123);
	D0_6 = _mm512_madd52hi_epu64(D0_6,a5122,b5123);
	D0_6 = _mm512_madd52lo_epu64(D0_6,a5122,b5124);
	D0_7 = _mm512_madd52hi_epu64(D0_7,a5122,b5124);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5122,b5125);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5122,b5125);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5122,b5126);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5122,b5126);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5122,b5127);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5122,b5127);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5122,b5128);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5122,b5128);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5122,b5129);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5122,b5129);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5122,b51210);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5122,b51210);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5122,b51211);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5122,b51211);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5122,b51212);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5122,b51212);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5122,b51213);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5122,b51213);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5122,b51214);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5122,b51214);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5122,b51215);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5122,b51215);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5122,b51216);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5122,b51216);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5122,b51217);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5122,b51217);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5122,b51218);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5122,b51218);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5122,b51219);
	D0_22 = _mm512_madd52hi_epu64(zero,a5122,b51219);

	D0_3 = _mm512_madd52lo_epu64(D0_3,a5123,b5120);
	D0_4 = _mm512_madd52hi_epu64(D0_4,a5123,b5120);
	D0_4 = _mm512_madd52lo_epu64(D0_4,a5123,b5121);
	D0_5 = _mm512_madd52hi_epu64(D0_5,a5123,b5121);
	D0_5 = _mm512_madd52lo_epu64(D0_5,a5123,b5122);
	D0_6 = _mm512_madd52hi_epu64(D0_6,a5123,b5122);
	D0_6 = _mm512_madd52lo_epu64(D0_6,a5123,b5123);
	D0_7 = _mm512_madd52hi_epu64(D0_7,a5123,b5123);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5123,b5124);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5123,b5124);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5123,b5125);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5123,b5125);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5123,b5126);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5123,b5126);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5123,b5127);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5123,b5127);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5123,b5128);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5123,b5128);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5123,b5129);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5123,b5129);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5123,b51210);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5123,b51210);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5123,b51211);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5123,b51211);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5123,b51212);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5123,b51212);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5123,b51213);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5123,b51213);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5123,b51214);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5123,b51214);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5123,b51215);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5123,b51215);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5123,b51216);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5123,b51216);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5123,b51217);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5123,b51217);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5123,b51218);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5123,b51218);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5123,b51219);
	D0_23 = _mm512_madd52hi_epu64(zero,a5123,b51219);

	D0_4 = _mm512_madd52lo_epu64(D0_4,a5124,b5120);
	D0_5 = _mm512_madd52hi_epu64(D0_5,a5124,b5120);
	D0_5 = _mm512_madd52lo_epu64(D0_5,a5124,b5121);
	D0_6 = _mm512_madd52hi_epu64(D0_6,a5124,b5121);
	D0_6 = _mm512_madd52lo_epu64(D0_6,a5124,b5122);
	D0_7 = _mm512_madd52hi_epu64(D0_7,a5124,b5122);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5124,b5123);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5124,b5123);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5124,b5124);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5124,b5124);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5124,b5125);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5124,b5125);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5124,b5126);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5124,b5126);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5124,b5127);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5124,b5127);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5124,b5128);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5124,b5128);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5124,b5129);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5124,b5129);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5124,b51210);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5124,b51210);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5124,b51211);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5124,b51211);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5124,b51212);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5124,b51212);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5124,b51213);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5124,b51213);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5124,b51214);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5124,b51214);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5124,b51215);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5124,b51215);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5124,b51216);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5124,b51216);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5124,b51217);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5124,b51217);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5124,b51218);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a5124,b51218);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a5124,b51219);
	D0_24 = _mm512_madd52hi_epu64(zero,a5124,b51219);

	D0_5 = _mm512_madd52lo_epu64(D0_5,a5125,b5120);
	D0_6 = _mm512_madd52hi_epu64(D0_6,a5125,b5120);
	D0_6 = _mm512_madd52lo_epu64(D0_6,a5125,b5121);
	D0_7 = _mm512_madd52hi_epu64(D0_7,a5125,b5121);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5125,b5122);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5125,b5122);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5125,b5123);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5125,b5123);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5125,b5124);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5125,b5124);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5125,b5125);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5125,b5125);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5125,b5126);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5125,b5126);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5125,b5127);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5125,b5127);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5125,b5128);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5125,b5128);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5125,b5129);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5125,b5129);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5125,b51210);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5125,b51210);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5125,b51211);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5125,b51211);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5125,b51212);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5125,b51212);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5125,b51213);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5125,b51213);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5125,b51214);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5125,b51214);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5125,b51215);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5125,b51215);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5125,b51216);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5125,b51216);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5125,b51217);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a5125,b51217);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a5125,b51218);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a5125,b51218);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a5125,b51219);
	D0_25 = _mm512_madd52hi_epu64(zero,a5125,b51219);

	D0_6 = _mm512_madd52lo_epu64(D0_6,a5126,b5120);
	D0_7 = _mm512_madd52hi_epu64(D0_7,a5126,b5120);
	D0_7 = _mm512_madd52lo_epu64(D0_7,a5126,b5121);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5126,b5121);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5126,b5122);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5126,b5122);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5126,b5123);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5126,b5123);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5126,b5124);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5126,b5124);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5126,b5125);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5126,b5125);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5126,b5126);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5126,b5126);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5126,b5127);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5126,b5127);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5126,b5128);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5126,b5128);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5126,b5129);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5126,b5129);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5126,b51210);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5126,b51210);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5126,b51211);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5126,b51211);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5126,b51212);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5126,b51212);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5126,b51213);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5126,b51213);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5126,b51214);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5126,b51214);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5126,b51215);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5126,b51215);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5126,b51216);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a5126,b51216);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a5126,b51217);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a5126,b51217);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a5126,b51218);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a5126,b51218);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a5126,b51219);
	D0_26 = _mm512_madd52hi_epu64(zero,a5126,b51219);

	D0_7 = _mm512_madd52lo_epu64(D0_7,a5127,b5120);
	D0_8 = _mm512_madd52hi_epu64(D0_8,a5127,b5120);
	D0_8 = _mm512_madd52lo_epu64(D0_8,a5127,b5121);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5127,b5121);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5127,b5122);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5127,b5122);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5127,b5123);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5127,b5123);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5127,b5124);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5127,b5124);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5127,b5125);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5127,b5125);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5127,b5126);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5127,b5126);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5127,b5127);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5127,b5127);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5127,b5128);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5127,b5128);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5127,b5129);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5127,b5129);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5127,b51210);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5127,b51210);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5127,b51211);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5127,b51211);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5127,b51212);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5127,b51212);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5127,b51213);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5127,b51213);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5127,b51214);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5127,b51214);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5127,b51215);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a5127,b51215);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a5127,b51216);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a5127,b51216);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a5127,b51217);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a5127,b51217);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a5127,b51218);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a5127,b51218);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a5127,b51219);
	D0_27 = _mm512_madd52hi_epu64(zero,a5127,b51219);

	D0_8 = _mm512_madd52lo_epu64(D0_8,a5128,b5120);
	D0_9 = _mm512_madd52hi_epu64(D0_9,a5128,b5120);
	D0_9 = _mm512_madd52lo_epu64(D0_9,a5128,b5121);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5128,b5121);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5128,b5122);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5128,b5122);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5128,b5123);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5128,b5123);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5128,b5124);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5128,b5124);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5128,b5125);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5128,b5125);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5128,b5126);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5128,b5126);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5128,b5127);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5128,b5127);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5128,b5128);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5128,b5128);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5128,b5129);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5128,b5129);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5128,b51210);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5128,b51210);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5128,b51211);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5128,b51211);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5128,b51212);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5128,b51212);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5128,b51213);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5128,b51213);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5128,b51214);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a5128,b51214);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a5128,b51215);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a5128,b51215);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a5128,b51216);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a5128,b51216);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a5128,b51217);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a5128,b51217);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a5128,b51218);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a5128,b51218);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a5128,b51219);
	D0_28 = _mm512_madd52hi_epu64(zero,a5128,b51219);

	D0_9 = _mm512_madd52lo_epu64(D0_9,a5129,b5120);
	D0_10 = _mm512_madd52hi_epu64(D0_10,a5129,b5120);
	D0_10 = _mm512_madd52lo_epu64(D0_10,a5129,b5121);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a5129,b5121);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a5129,b5122);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a5129,b5122);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a5129,b5123);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a5129,b5123);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a5129,b5124);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a5129,b5124);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a5129,b5125);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a5129,b5125);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a5129,b5126);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a5129,b5126);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a5129,b5127);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a5129,b5127);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a5129,b5128);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a5129,b5128);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a5129,b5129);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a5129,b5129);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a5129,b51210);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a5129,b51210);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a5129,b51211);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a5129,b51211);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a5129,b51212);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a5129,b51212);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a5129,b51213);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a5129,b51213);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a5129,b51214);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a5129,b51214);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a5129,b51215);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a5129,b51215);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a5129,b51216);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a5129,b51216);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a5129,b51217);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a5129,b51217);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a5129,b51218);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a5129,b51218);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a5129,b51219);
	D0_29 = _mm512_madd52hi_epu64(zero,a5129,b51219);

	D0_10 = _mm512_madd52lo_epu64(D0_10,a51210,b5120);
	D0_11 = _mm512_madd52hi_epu64(D0_11,a51210,b5120);
	D0_11 = _mm512_madd52lo_epu64(D0_11,a51210,b5121);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a51210,b5121);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a51210,b5122);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a51210,b5122);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a51210,b5123);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a51210,b5123);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a51210,b5124);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a51210,b5124);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a51210,b5125);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a51210,b5125);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a51210,b5126);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51210,b5126);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51210,b5127);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51210,b5127);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51210,b5128);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51210,b5128);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51210,b5129);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51210,b5129);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51210,b51210);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51210,b51210);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51210,b51211);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51210,b51211);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51210,b51212);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51210,b51212);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51210,b51213);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51210,b51213);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51210,b51214);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51210,b51214);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51210,b51215);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51210,b51215);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51210,b51216);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51210,b51216);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51210,b51217);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51210,b51217);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51210,b51218);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51210,b51218);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51210,b51219);
	D0_30 = _mm512_madd52hi_epu64(zero,a51210,b51219);

	D0_11 = _mm512_madd52lo_epu64(D0_11,a51211,b5120);
	D0_12 = _mm512_madd52hi_epu64(D0_12,a51211,b5120);
	D0_12 = _mm512_madd52lo_epu64(D0_12,a51211,b5121);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a51211,b5121);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a51211,b5122);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a51211,b5122);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a51211,b5123);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a51211,b5123);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a51211,b5124);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a51211,b5124);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a51211,b5125);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51211,b5125);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51211,b5126);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51211,b5126);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51211,b5127);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51211,b5127);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51211,b5128);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51211,b5128);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51211,b5129);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51211,b5129);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51211,b51210);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51211,b51210);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51211,b51211);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51211,b51211);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51211,b51212);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51211,b51212);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51211,b51213);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51211,b51213);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51211,b51214);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51211,b51214);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51211,b51215);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51211,b51215);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51211,b51216);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51211,b51216);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51211,b51217);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51211,b51217);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51211,b51218);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51211,b51218);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51211,b51219);
	D0_31 = _mm512_madd52hi_epu64(zero,a51211,b51219);

	D0_12 = _mm512_madd52lo_epu64(D0_12,a51212,b5120);
	D0_13 = _mm512_madd52hi_epu64(D0_13,a51212,b5120);
	D0_13 = _mm512_madd52lo_epu64(D0_13,a51212,b5121);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a51212,b5121);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a51212,b5122);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a51212,b5122);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a51212,b5123);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a51212,b5123);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a51212,b5124);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51212,b5124);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51212,b5125);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51212,b5125);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51212,b5126);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51212,b5126);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51212,b5127);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51212,b5127);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51212,b5128);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51212,b5128);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51212,b5129);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51212,b5129);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51212,b51210);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51212,b51210);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51212,b51211);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51212,b51211);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51212,b51212);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51212,b51212);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51212,b51213);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51212,b51213);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51212,b51214);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51212,b51214);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51212,b51215);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51212,b51215);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51212,b51216);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51212,b51216);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51212,b51217);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51212,b51217);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51212,b51218);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51212,b51218);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51212,b51219);
	D0_32 = _mm512_madd52hi_epu64(zero,a51212,b51219);

	D0_13 = _mm512_madd52lo_epu64(D0_13,a51213,b5120);
	D0_14 = _mm512_madd52hi_epu64(D0_14,a51213,b5120);
	D0_14 = _mm512_madd52lo_epu64(D0_14,a51213,b5121);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a51213,b5121);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a51213,b5122);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a51213,b5122);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a51213,b5123);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51213,b5123);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51213,b5124);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51213,b5124);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51213,b5125);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51213,b5125);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51213,b5126);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51213,b5126);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51213,b5127);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51213,b5127);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51213,b5128);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51213,b5128);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51213,b5129);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51213,b5129);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51213,b51210);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51213,b51210);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51213,b51211);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51213,b51211);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51213,b51212);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51213,b51212);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51213,b51213);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51213,b51213);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51213,b51214);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51213,b51214);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51213,b51215);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51213,b51215);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51213,b51216);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51213,b51216);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51213,b51217);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51213,b51217);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51213,b51218);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51213,b51218);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51213,b51219);
	D0_33 = _mm512_madd52hi_epu64(zero,a51213,b51219);

	D0_14 = _mm512_madd52lo_epu64(D0_14,a51214,b5120);
	D0_15 = _mm512_madd52hi_epu64(D0_15,a51214,b5120);
	D0_15 = _mm512_madd52lo_epu64(D0_15,a51214,b5121);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a51214,b5121);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a51214,b5122);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51214,b5122);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51214,b5123);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51214,b5123);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51214,b5124);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51214,b5124);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51214,b5125);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51214,b5125);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51214,b5126);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51214,b5126);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51214,b5127);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51214,b5127);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51214,b5128);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51214,b5128);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51214,b5129);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51214,b5129);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51214,b51210);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51214,b51210);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51214,b51211);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51214,b51211);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51214,b51212);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51214,b51212);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51214,b51213);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51214,b51213);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51214,b51214);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51214,b51214);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51214,b51215);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51214,b51215);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51214,b51216);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51214,b51216);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51214,b51217);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51214,b51217);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51214,b51218);
	D0_33 = _mm512_madd52hi_epu64(D0_33,a51214,b51218);
	D0_33 = _mm512_madd52lo_epu64(D0_33,a51214,b51219);
	D0_34 = _mm512_madd52hi_epu64(zero,a51214,b51219);

	D0_15 = _mm512_madd52lo_epu64(D0_15,a51215,b5120);
	D0_16 = _mm512_madd52hi_epu64(D0_16,a51215,b5120);
	D0_16 = _mm512_madd52lo_epu64(D0_16,a51215,b5121);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51215,b5121);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51215,b5122);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51215,b5122);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51215,b5123);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51215,b5123);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51215,b5124);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51215,b5124);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51215,b5125);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51215,b5125);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51215,b5126);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51215,b5126);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51215,b5127);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51215,b5127);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51215,b5128);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51215,b5128);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51215,b5129);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51215,b5129);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51215,b51210);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51215,b51210);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51215,b51211);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51215,b51211);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51215,b51212);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51215,b51212);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51215,b51213);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51215,b51213);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51215,b51214);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51215,b51214);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51215,b51215);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51215,b51215);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51215,b51216);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51215,b51216);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51215,b51217);
	D0_33 = _mm512_madd52hi_epu64(D0_33,a51215,b51217);
	D0_33 = _mm512_madd52lo_epu64(D0_33,a51215,b51218);
	D0_34 = _mm512_madd52hi_epu64(D0_34,a51215,b51218);
	D0_34 = _mm512_madd52lo_epu64(D0_34,a51215,b51219);
	D0_35 = _mm512_madd52hi_epu64(zero,a51215,b51219);

	D0_16 = _mm512_madd52lo_epu64(D0_16,a51216,b5120);
	D0_17 = _mm512_madd52hi_epu64(D0_17,a51216,b5120);
	D0_17 = _mm512_madd52lo_epu64(D0_17,a51216,b5121);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51216,b5121);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51216,b5122);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51216,b5122);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51216,b5123);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51216,b5123);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51216,b5124);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51216,b5124);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51216,b5125);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51216,b5125);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51216,b5126);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51216,b5126);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51216,b5127);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51216,b5127);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51216,b5128);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51216,b5128);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51216,b5129);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51216,b5129);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51216,b51210);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51216,b51210);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51216,b51211);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51216,b51211);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51216,b51212);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51216,b51212);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51216,b51213);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51216,b51213);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51216,b51214);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51216,b51214);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51216,b51215);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51216,b51215);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51216,b51216);
	D0_33 = _mm512_madd52hi_epu64(D0_33,a51216,b51216);
	D0_33 = _mm512_madd52lo_epu64(D0_33,a51216,b51217);
	D0_34 = _mm512_madd52hi_epu64(D0_34,a51216,b51217);
	D0_34 = _mm512_madd52lo_epu64(D0_34,a51216,b51218);
	D0_35 = _mm512_madd52hi_epu64(D0_35,a51216,b51218);
	D0_35 = _mm512_madd52lo_epu64(D0_35,a51216,b51219);
	D0_36 = _mm512_madd52hi_epu64(zero,a51216,b51219);

	D0_17 = _mm512_madd52lo_epu64(D0_17,a51217,b5120);
	D0_18 = _mm512_madd52hi_epu64(D0_18,a51217,b5120);
	D0_18 = _mm512_madd52lo_epu64(D0_18,a51217,b5121);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51217,b5121);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51217,b5122);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51217,b5122);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51217,b5123);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51217,b5123);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51217,b5124);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51217,b5124);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51217,b5125);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51217,b5125);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51217,b5126);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51217,b5126);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51217,b5127);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51217,b5127);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51217,b5128);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51217,b5128);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51217,b5129);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51217,b5129);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51217,b51210);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51217,b51210);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51217,b51211);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51217,b51211);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51217,b51212);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51217,b51212);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51217,b51213);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51217,b51213);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51217,b51214);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51217,b51214);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51217,b51215);
	D0_33 = _mm512_madd52hi_epu64(D0_33,a51217,b51215);
	D0_33 = _mm512_madd52lo_epu64(D0_33,a51217,b51216);
	D0_34 = _mm512_madd52hi_epu64(D0_34,a51217,b51216);
	D0_34 = _mm512_madd52lo_epu64(D0_34,a51217,b51217);
	D0_35 = _mm512_madd52hi_epu64(D0_35,a51217,b51217);
	D0_35 = _mm512_madd52lo_epu64(D0_35,a51217,b51218);
	D0_36 = _mm512_madd52hi_epu64(D0_36,a51217,b51218);
	D0_36 = _mm512_madd52lo_epu64(D0_36,a51217,b51219);
	D0_37 = _mm512_madd52hi_epu64(zero,a51217,b51219);

	D0_18 = _mm512_madd52lo_epu64(D0_18,a51218,b5120);
	D0_19 = _mm512_madd52hi_epu64(D0_19,a51218,b5120);
	D0_19 = _mm512_madd52lo_epu64(D0_19,a51218,b5121);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51218,b5121);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51218,b5122);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51218,b5122);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51218,b5123);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51218,b5123);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51218,b5124);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51218,b5124);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51218,b5125);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51218,b5125);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51218,b5126);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51218,b5126);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51218,b5127);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51218,b5127);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51218,b5128);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51218,b5128);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51218,b5129);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51218,b5129);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51218,b51210);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51218,b51210);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51218,b51211);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51218,b51211);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51218,b51212);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51218,b51212);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51218,b51213);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51218,b51213);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51218,b51214);
	D0_33 = _mm512_madd52hi_epu64(D0_33,a51218,b51214);
	D0_33 = _mm512_madd52lo_epu64(D0_33,a51218,b51215);
	D0_34 = _mm512_madd52hi_epu64(D0_34,a51218,b51215);
	D0_34 = _mm512_madd52lo_epu64(D0_34,a51218,b51216);
	D0_35 = _mm512_madd52hi_epu64(D0_35,a51218,b51216);
	D0_35 = _mm512_madd52lo_epu64(D0_35,a51218,b51217);
	D0_36 = _mm512_madd52hi_epu64(D0_36,a51218,b51217);
	D0_36 = _mm512_madd52lo_epu64(D0_36,a51218,b51218);
	D0_37 = _mm512_madd52hi_epu64(D0_37,a51218,b51218);
	D0_37 = _mm512_madd52lo_epu64(D0_37,a51218,b51219);
	D0_38 = _mm512_madd52hi_epu64(zero,a51218,b51219);

	D0_19 = _mm512_madd52lo_epu64(D0_19,a51219,b5120);
	D0_20 = _mm512_madd52hi_epu64(D0_20,a51219,b5120);
	D0_20 = _mm512_madd52lo_epu64(D0_20,a51219,b5121);
	D0_21 = _mm512_madd52hi_epu64(D0_21,a51219,b5121);
	D0_21 = _mm512_madd52lo_epu64(D0_21,a51219,b5122);
	D0_22 = _mm512_madd52hi_epu64(D0_22,a51219,b5122);
	D0_22 = _mm512_madd52lo_epu64(D0_22,a51219,b5123);
	D0_23 = _mm512_madd52hi_epu64(D0_23,a51219,b5123);
	D0_23 = _mm512_madd52lo_epu64(D0_23,a51219,b5124);
	D0_24 = _mm512_madd52hi_epu64(D0_24,a51219,b5124);
	D0_24 = _mm512_madd52lo_epu64(D0_24,a51219,b5125);
	D0_25 = _mm512_madd52hi_epu64(D0_25,a51219,b5125);
	D0_25 = _mm512_madd52lo_epu64(D0_25,a51219,b5126);
	D0_26 = _mm512_madd52hi_epu64(D0_26,a51219,b5126);
	D0_26 = _mm512_madd52lo_epu64(D0_26,a51219,b5127);
	D0_27 = _mm512_madd52hi_epu64(D0_27,a51219,b5127);
	D0_27 = _mm512_madd52lo_epu64(D0_27,a51219,b5128);
	D0_28 = _mm512_madd52hi_epu64(D0_28,a51219,b5128);
	D0_28 = _mm512_madd52lo_epu64(D0_28,a51219,b5129);
	D0_29 = _mm512_madd52hi_epu64(D0_29,a51219,b5129);
	D0_29 = _mm512_madd52lo_epu64(D0_29,a51219,b51210);
	D0_30 = _mm512_madd52hi_epu64(D0_30,a51219,b51210);
	D0_30 = _mm512_madd52lo_epu64(D0_30,a51219,b51211);
	D0_31 = _mm512_madd52hi_epu64(D0_31,a51219,b51211);
	D0_31 = _mm512_madd52lo_epu64(D0_31,a51219,b51212);
	D0_32 = _mm512_madd52hi_epu64(D0_32,a51219,b51212);
	D0_32 = _mm512_madd52lo_epu64(D0_32,a51219,b51213);
	D0_33 = _mm512_madd52hi_epu64(D0_33,a51219,b51213);
	D0_33 = _mm512_madd52lo_epu64(D0_33,a51219,b51214);
	D0_34 = _mm512_madd52hi_epu64(D0_34,a51219,b51214);
	D0_34 = _mm512_madd52lo_epu64(D0_34,a51219,b51215);
	D0_35 = _mm512_madd52hi_epu64(D0_35,a51219,b51215);
	D0_35 = _mm512_madd52lo_epu64(D0_35,a51219,b51216);
	D0_36 = _mm512_madd52hi_epu64(D0_36,a51219,b51216);
	D0_36 = _mm512_madd52lo_epu64(D0_36,a51219,b51217);
	D0_37 = _mm512_madd52hi_epu64(D0_37,a51219,b51217);
	D0_37 = _mm512_madd52lo_epu64(D0_37,a51219,b51218);
	D0_38 = _mm512_madd52hi_epu64(D0_38,a51219,b51218);
	D0_38 = _mm512_madd52lo_epu64(D0_38,a51219,b51219);
	D0_39 = _mm512_madd52hi_epu64(zero,a51219,b51219);


	// Carry management

	__m512i carry  = _mm512_srli_epi64(D0_1,52);
	D0_2 = _mm512_add_epi64(D0_2,carry);
	D0_1 = _mm512_and_si512(D0_1,mask52);
	carry  = _mm512_srli_epi64(D0_2,52);
	D0_3 = _mm512_add_epi64(D0_3,carry);
	D0_2 = _mm512_and_si512(D0_2,mask52);
	carry  = _mm512_srli_epi64(D0_3,52);
	D0_4 = _mm512_add_epi64(D0_4,carry);
	D0_3 = _mm512_and_si512(D0_3,mask52);
	carry  = _mm512_srli_epi64(D0_4,52);
	D0_5 = _mm512_add_epi64(D0_5,carry);
	D0_4 = _mm512_and_si512(D0_4,mask52);
	carry  = _mm512_srli_epi64(D0_5,52);
	D0_6 = _mm512_add_epi64(D0_6,carry);
	D0_5 = _mm512_and_si512(D0_5,mask52);
	carry  = _mm512_srli_epi64(D0_6,52);
	D0_7 = _mm512_add_epi64(D0_7,carry);
	D0_6 = _mm512_and_si512(D0_6,mask52);
	carry  = _mm512_srli_epi64(D0_7,52);
	D0_8 = _mm512_add_epi64(D0_8,carry);
	D0_7 = _mm512_and_si512(D0_7,mask52);
	carry  = _mm512_srli_epi64(D0_8,52);
	D0_9 = _mm512_add_epi64(D0_9,carry);
	D0_8 = _mm512_and_si512(D0_8,mask52);
	carry  = _mm512_srli_epi64(D0_9,52);
	D0_10 = _mm512_add_epi64(D0_10,carry);
	D0_9 = _mm512_and_si512(D0_9,mask52);
	carry  = _mm512_srli_epi64(D0_10,52);
	D0_11 = _mm512_add_epi64(D0_11,carry);
	D0_10 = _mm512_and_si512(D0_10,mask52);
	carry  = _mm512_srli_epi64(D0_11,52);
	D0_12 = _mm512_add_epi64(D0_12,carry);
	D0_11 = _mm512_and_si512(D0_11,mask52);
	carry  = _mm512_srli_epi64(D0_12,52);
	D0_13 = _mm512_add_epi64(D0_13,carry);
	D0_12 = _mm512_and_si512(D0_12,mask52);
	carry  = _mm512_srli_epi64(D0_13,52);
	D0_14 = _mm512_add_epi64(D0_14,carry);
	D0_13 = _mm512_and_si512(D0_13,mask52);
	carry  = _mm512_srli_epi64(D0_14,52);
	D0_15 = _mm512_add_epi64(D0_15,carry);
	D0_14 = _mm512_and_si512(D0_14,mask52);
	carry  = _mm512_srli_epi64(D0_15,52);
	D0_16 = _mm512_add_epi64(D0_16,carry);
	D0_15 = _mm512_and_si512(D0_15,mask52);
	carry  = _mm512_srli_epi64(D0_16,52);
	D0_17 = _mm512_add_epi64(D0_17,carry);
	D0_16 = _mm512_and_si512(D0_16,mask52);
	carry  = _mm512_srli_epi64(D0_17,52);
	D0_18 = _mm512_add_epi64(D0_18,carry);
	D0_17 = _mm512_and_si512(D0_17,mask52);
	carry  = _mm512_srli_epi64(D0_18,52);
	D0_19 = _mm512_add_epi64(D0_19,carry);
	D0_18 = _mm512_and_si512(D0_18,mask52);
	/*carry  = _mm512_srli_epi64(D0_19,52);
	D0_20 = _mm512_add_epi64(D0_20,carry);
	D0_19 = _mm512_and_si512(D0_19,mask52);
	carry  = _mm512_srli_epi64(D0_20,52);
	D0_21 = _mm512_add_epi64(D0_21,carry);
	D0_20 = _mm512_and_si512(D0_20,mask52);
	carry  = _mm512_srli_epi64(D0_21,52);
	D0_22 = _mm512_add_epi64(D0_22,carry);
	D0_21 = _mm512_and_si512(D0_21,mask52);
	carry  = _mm512_srli_epi64(D0_22,52);
	D0_23 = _mm512_add_epi64(D0_23,carry);
	D0_22 = _mm512_and_si512(D0_22,mask52);
	carry  = _mm512_srli_epi64(D0_23,52);
	D0_24 = _mm512_add_epi64(D0_24,carry);
	D0_23 = _mm512_and_si512(D0_23,mask52);
	carry  = _mm512_srli_epi64(D0_24,52);
	D0_25 = _mm512_add_epi64(D0_25,carry);
	D0_24 = _mm512_and_si512(D0_24,mask52);
	carry  = _mm512_srli_epi64(D0_25,52);
	D0_26 = _mm512_add_epi64(D0_26,carry);
	D0_25 = _mm512_and_si512(D0_25,mask52);
	carry  = _mm512_srli_epi64(D0_26,52);
	D0_27 = _mm512_add_epi64(D0_27,carry);
	D0_26 = _mm512_and_si512(D0_26,mask52);
	carry  = _mm512_srli_epi64(D0_27,52);
	D0_28 = _mm512_add_epi64(D0_28,carry);
	D0_27 = _mm512_and_si512(D0_27,mask52);
	carry  = _mm512_srli_epi64(D0_28,52);
	D0_29 = _mm512_add_epi64(D0_29,carry);
	D0_28 = _mm512_and_si512(D0_28,mask52);
	carry  = _mm512_srli_epi64(D0_29,52);
	D0_30 = _mm512_add_epi64(D0_30,carry);
	D0_29 = _mm512_and_si512(D0_29,mask52);
	carry  = _mm512_srli_epi64(D0_30,52);
	D0_31 = _mm512_add_epi64(D0_31,carry);
	D0_30 = _mm512_and_si512(D0_30,mask52);
	carry  = _mm512_srli_epi64(D0_31,52);
	D0_32 = _mm512_add_epi64(D0_32,carry);
	D0_31 = _mm512_and_si512(D0_31,mask52);
	carry  = _mm512_srli_epi64(D0_32,52);
	D0_33 = _mm512_add_epi64(D0_33,carry);
	D0_32 = _mm512_and_si512(D0_32,mask52);
	carry  = _mm512_srli_epi64(D0_33,52);
	D0_34 = _mm512_add_epi64(D0_34,carry);
	D0_33 = _mm512_and_si512(D0_33,mask52);
	carry  = _mm512_srli_epi64(D0_34,52);
	D0_35 = _mm512_add_epi64(D0_35,carry);
	D0_34 = _mm512_and_si512(D0_34,mask52);
	carry  = _mm512_srli_epi64(D0_35,52);
	D0_36 = _mm512_add_epi64(D0_36,carry);
	D0_35 = _mm512_and_si512(D0_35,mask52);
	carry  = _mm512_srli_epi64(D0_36,52);
	D0_37 = _mm512_add_epi64(D0_37,carry);
	D0_36 = _mm512_and_si512(D0_36,mask52);
	carry  = _mm512_srli_epi64(D0_37,52);
	D0_38 = _mm512_add_epi64(D0_38,carry);
	D0_37 = _mm512_and_si512(D0_37,mask52);
	carry  = _mm512_srli_epi64(D0_38,52);
	D0_39 = _mm512_add_epi64(D0_39,carry);
	D0_38 = _mm512_and_si512(D0_38,mask52);//*/

	// Conversion in base 2^1039

	carry = D0_19>>51;
	D0_20 = (D0_20<<1)+carry;
	D0_19 &= mask51;
	carry = D0_20>>52;
	D0_21 = (D0_21<<1)+carry;
	D0_20 &= mask52;
	carry = D0_21>>52;
	D0_22 = (D0_22<<1)+carry;
	D0_21 &= mask52;
	carry = D0_22>>52;
	D0_23 = (D0_23<<1)+carry;
	D0_22 &= mask52;
	carry = D0_23>>52;
	D0_24 = (D0_24<<1)+carry;
	D0_23 &= mask52;
	carry = D0_24>>52;
	D0_25 = (D0_25<<1)+carry;
	D0_24 &= mask52;
	carry = D0_25>>52;
	D0_26 = (D0_26<<1)+carry;
	D0_25 &= mask52;
	carry = D0_26>>52;
	D0_27 = (D0_27<<1)+carry;
	D0_26 &= mask52;
	carry = D0_27>>52;
	D0_28 = (D0_28<<1)+carry;
	D0_27 &= mask52;
	carry = D0_28>>52;
	D0_29 = (D0_29<<1)+carry;
	D0_28 &= mask52;
	carry = D0_29>>52;
	D0_30 = (D0_30<<1)+carry;
	D0_29 &= mask52;
	carry = D0_30>>52;
	D0_31 = (D0_31<<1)+carry;
	D0_30 &= mask52;
	carry = D0_31>>52;
	D0_32 = (D0_32<<1)+carry;
	D0_31 &= mask52;
	carry = D0_32>>52;
	D0_33 = (D0_33<<1)+carry;
	D0_32 &= mask52;
	carry = D0_33>>52;
	D0_34 = (D0_34<<1)+carry;
	D0_33 &= mask52;
	carry = D0_34>>52;
	D0_35 = (D0_35<<1)+carry;
	D0_34 &= mask52;
	carry = D0_35>>52;
	D0_36 = (D0_36<<1)+carry;
	D0_35 &= mask52;
	carry = D0_36>>52;
	D0_37 = (D0_37<<1)+carry;
	D0_36 &= mask52;
	carry = D0_37>>52;
	D0_38 = (D0_38<<1)+carry;
	D0_37 &= mask52;
	carry = D0_38>>52;
	D0_39 = (D0_39<<1)+carry;
	D0_38 &= mask52;

	// D2 = Ah*Bh

	__m512i D2_0;
	__m512i D2_1;
	__m512i D2_2;
	__m512i D2_3;
	__m512i D2_4;
	__m512i D2_5;
	__m512i D2_6;
	__m512i D2_7;
	__m512i D2_8;
	__m512i D2_9;
	__m512i D2_10;
	__m512i D2_11;
	__m512i D2_12;
	__m512i D2_13;
	__m512i D2_14;
	__m512i D2_15;
	__m512i D2_16;
	__m512i D2_17;
	__m512i D2_18;
	__m512i D2_19;
	__m512i a51220 = _mm512_load_epi64(a512+20), b51220 = _mm512_load_epi64(b512+20);
	__m512i a51221 = _mm512_load_epi64(a512+21), b51221 = _mm512_load_epi64(b512+21);
	__m512i a51222 = _mm512_load_epi64(a512+22), b51222 = _mm512_load_epi64(b512+22);
	__m512i a51223 = _mm512_load_epi64(a512+23), b51223 = _mm512_load_epi64(b512+23);
	__m512i a51224 = _mm512_load_epi64(a512+24), b51224 = _mm512_load_epi64(b512+24);
	__m512i a51225 = _mm512_load_epi64(a512+25), b51225 = _mm512_load_epi64(b512+25);
	__m512i a51226 = _mm512_load_epi64(a512+26), b51226 = _mm512_load_epi64(b512+26);
	__m512i a51227 = _mm512_load_epi64(a512+27), b51227 = _mm512_load_epi64(b512+27);
	__m512i a51228 = _mm512_load_epi64(a512+28), b51228 = _mm512_load_epi64(b512+28);
	__m512i a51229 = _mm512_load_epi64(a512+29), b51229 = _mm512_load_epi64(b512+29);
	__m512i a51230 = _mm512_load_epi64(a512+30), b51230 = _mm512_load_epi64(b512+30);
	__m512i a51231 = _mm512_load_epi64(a512+31), b51231 = _mm512_load_epi64(b512+31);
	__m512i a51232 = _mm512_load_epi64(a512+32), b51232 = _mm512_load_epi64(b512+32);
	__m512i a51233 = _mm512_load_epi64(a512+33), b51233 = _mm512_load_epi64(b512+33);
	__m512i a51234 = _mm512_load_epi64(a512+34), b51234 = _mm512_load_epi64(b512+34);
	__m512i a51235 = _mm512_load_epi64(a512+35), b51235 = _mm512_load_epi64(b512+35);
	__m512i a51236 = _mm512_load_epi64(a512+36), b51236 = _mm512_load_epi64(b512+36);
	__m512i a51237 = _mm512_load_epi64(a512+37), b51237 = _mm512_load_epi64(b512+37);
	__m512i a51238 = _mm512_load_epi64(a512+38), b51238 = _mm512_load_epi64(b512+38);
	__m512i a51239 = _mm512_load_epi64(a512+39), b51239 = _mm512_load_epi64(b512+39);
	D2_0 = _mm512_madd52lo_epu64(zero,a51220,b51220);
	D2_1 = _mm512_madd52hi_epu64(zero,a51220,b51220);
	D2_1 = _mm512_madd52lo_epu64(D2_1,a51220,b51221);
	D2_2 = _mm512_madd52hi_epu64(zero,a51220,b51221);
	D2_2 = _mm512_madd52lo_epu64(D2_2,a51220,b51222);
	D2_3 = _mm512_madd52hi_epu64(zero,a51220,b51222);
	D2_3 = _mm512_madd52lo_epu64(D2_3,a51220,b51223);
	D2_4 = _mm512_madd52hi_epu64(zero,a51220,b51223);
	D2_4 = _mm512_madd52lo_epu64(D2_4,a51220,b51224);
	D2_5 = _mm512_madd52hi_epu64(zero,a51220,b51224);
	D2_5 = _mm512_madd52lo_epu64(D2_5,a51220,b51225);
	D2_6 = _mm512_madd52hi_epu64(zero,a51220,b51225);
	D2_6 = _mm512_madd52lo_epu64(D2_6,a51220,b51226);
	D2_7 = _mm512_madd52hi_epu64(zero,a51220,b51226);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51220,b51227);
	D2_8 = _mm512_madd52hi_epu64(zero,a51220,b51227);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51220,b51228);
	D2_9 = _mm512_madd52hi_epu64(zero,a51220,b51228);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51220,b51229);
	D2_10 = _mm512_madd52hi_epu64(zero,a51220,b51229);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51220,b51230);
	D2_11 = _mm512_madd52hi_epu64(zero,a51220,b51230);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51220,b51231);
	D2_12 = _mm512_madd52hi_epu64(zero,a51220,b51231);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51220,b51232);
	D2_13 = _mm512_madd52hi_epu64(zero,a51220,b51232);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51220,b51233);
	D2_14 = _mm512_madd52hi_epu64(zero,a51220,b51233);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51220,b51234);
	D2_15 = _mm512_madd52hi_epu64(zero,a51220,b51234);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51220,b51235);
	D2_16 = _mm512_madd52hi_epu64(zero,a51220,b51235);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51220,b51236);
	D2_17 = _mm512_madd52hi_epu64(zero,a51220,b51236);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51220,b51237);
	D2_18 = _mm512_madd52hi_epu64(zero,a51220,b51237);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51220,b51238);
	D2_19 = _mm512_madd52hi_epu64(zero,a51220,b51238);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51220,b51239);

	D2_1 = _mm512_madd52lo_epu64(D2_1,a51221,b51220);
	D2_2 = _mm512_madd52hi_epu64(D2_2,a51221,b51220);
	D2_2 = _mm512_madd52lo_epu64(D2_2,a51221,b51221);
	D2_3 = _mm512_madd52hi_epu64(D2_3,a51221,b51221);
	D2_3 = _mm512_madd52lo_epu64(D2_3,a51221,b51222);
	D2_4 = _mm512_madd52hi_epu64(D2_4,a51221,b51222);
	D2_4 = _mm512_madd52lo_epu64(D2_4,a51221,b51223);
	D2_5 = _mm512_madd52hi_epu64(D2_5,a51221,b51223);
	D2_5 = _mm512_madd52lo_epu64(D2_5,a51221,b51224);
	D2_6 = _mm512_madd52hi_epu64(D2_6,a51221,b51224);
	D2_6 = _mm512_madd52lo_epu64(D2_6,a51221,b51225);
	D2_7 = _mm512_madd52hi_epu64(D2_7,a51221,b51225);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51221,b51226);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51221,b51226);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51221,b51227);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51221,b51227);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51221,b51228);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51221,b51228);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51221,b51229);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51221,b51229);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51221,b51230);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51221,b51230);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51221,b51231);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51221,b51231);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51221,b51232);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51221,b51232);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51221,b51233);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51221,b51233);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51221,b51234);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51221,b51234);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51221,b51235);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51221,b51235);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51221,b51236);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51221,b51236);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51221,b51237);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51221,b51237);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51221,b51238);

	D2_2 = _mm512_madd52lo_epu64(D2_2,a51222,b51220);
	D2_3 = _mm512_madd52hi_epu64(D2_3,a51222,b51220);
	D2_3 = _mm512_madd52lo_epu64(D2_3,a51222,b51221);
	D2_4 = _mm512_madd52hi_epu64(D2_4,a51222,b51221);
	D2_4 = _mm512_madd52lo_epu64(D2_4,a51222,b51222);
	D2_5 = _mm512_madd52hi_epu64(D2_5,a51222,b51222);
	D2_5 = _mm512_madd52lo_epu64(D2_5,a51222,b51223);
	D2_6 = _mm512_madd52hi_epu64(D2_6,a51222,b51223);
	D2_6 = _mm512_madd52lo_epu64(D2_6,a51222,b51224);
	D2_7 = _mm512_madd52hi_epu64(D2_7,a51222,b51224);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51222,b51225);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51222,b51225);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51222,b51226);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51222,b51226);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51222,b51227);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51222,b51227);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51222,b51228);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51222,b51228);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51222,b51229);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51222,b51229);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51222,b51230);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51222,b51230);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51222,b51231);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51222,b51231);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51222,b51232);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51222,b51232);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51222,b51233);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51222,b51233);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51222,b51234);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51222,b51234);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51222,b51235);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51222,b51235);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51222,b51236);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51222,b51236);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51222,b51237);

	D2_3 = _mm512_madd52lo_epu64(D2_3,a51223,b51220);
	D2_4 = _mm512_madd52hi_epu64(D2_4,a51223,b51220);
	D2_4 = _mm512_madd52lo_epu64(D2_4,a51223,b51221);
	D2_5 = _mm512_madd52hi_epu64(D2_5,a51223,b51221);
	D2_5 = _mm512_madd52lo_epu64(D2_5,a51223,b51222);
	D2_6 = _mm512_madd52hi_epu64(D2_6,a51223,b51222);
	D2_6 = _mm512_madd52lo_epu64(D2_6,a51223,b51223);
	D2_7 = _mm512_madd52hi_epu64(D2_7,a51223,b51223);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51223,b51224);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51223,b51224);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51223,b51225);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51223,b51225);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51223,b51226);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51223,b51226);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51223,b51227);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51223,b51227);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51223,b51228);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51223,b51228);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51223,b51229);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51223,b51229);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51223,b51230);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51223,b51230);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51223,b51231);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51223,b51231);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51223,b51232);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51223,b51232);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51223,b51233);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51223,b51233);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51223,b51234);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51223,b51234);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51223,b51235);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51223,b51235);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51223,b51236);

	D2_4 = _mm512_madd52lo_epu64(D2_4,a51224,b51220);
	D2_5 = _mm512_madd52hi_epu64(D2_5,a51224,b51220);
	D2_5 = _mm512_madd52lo_epu64(D2_5,a51224,b51221);
	D2_6 = _mm512_madd52hi_epu64(D2_6,a51224,b51221);
	D2_6 = _mm512_madd52lo_epu64(D2_6,a51224,b51222);
	D2_7 = _mm512_madd52hi_epu64(D2_7,a51224,b51222);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51224,b51223);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51224,b51223);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51224,b51224);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51224,b51224);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51224,b51225);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51224,b51225);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51224,b51226);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51224,b51226);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51224,b51227);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51224,b51227);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51224,b51228);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51224,b51228);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51224,b51229);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51224,b51229);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51224,b51230);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51224,b51230);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51224,b51231);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51224,b51231);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51224,b51232);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51224,b51232);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51224,b51233);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51224,b51233);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51224,b51234);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51224,b51234);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51224,b51235);

	D2_5 = _mm512_madd52lo_epu64(D2_5,a51225,b51220);
	D2_6 = _mm512_madd52hi_epu64(D2_6,a51225,b51220);
	D2_6 = _mm512_madd52lo_epu64(D2_6,a51225,b51221);
	D2_7 = _mm512_madd52hi_epu64(D2_7,a51225,b51221);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51225,b51222);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51225,b51222);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51225,b51223);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51225,b51223);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51225,b51224);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51225,b51224);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51225,b51225);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51225,b51225);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51225,b51226);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51225,b51226);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51225,b51227);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51225,b51227);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51225,b51228);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51225,b51228);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51225,b51229);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51225,b51229);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51225,b51230);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51225,b51230);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51225,b51231);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51225,b51231);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51225,b51232);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51225,b51232);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51225,b51233);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51225,b51233);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51225,b51234);

	D2_6 = _mm512_madd52lo_epu64(D2_6,a51226,b51220);
	D2_7 = _mm512_madd52hi_epu64(D2_7,a51226,b51220);
	D2_7 = _mm512_madd52lo_epu64(D2_7,a51226,b51221);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51226,b51221);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51226,b51222);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51226,b51222);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51226,b51223);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51226,b51223);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51226,b51224);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51226,b51224);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51226,b51225);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51226,b51225);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51226,b51226);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51226,b51226);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51226,b51227);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51226,b51227);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51226,b51228);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51226,b51228);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51226,b51229);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51226,b51229);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51226,b51230);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51226,b51230);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51226,b51231);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51226,b51231);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51226,b51232);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51226,b51232);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51226,b51233);

	D2_7 = _mm512_madd52lo_epu64(D2_7,a51227,b51220);
	D2_8 = _mm512_madd52hi_epu64(D2_8,a51227,b51220);
	D2_8 = _mm512_madd52lo_epu64(D2_8,a51227,b51221);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51227,b51221);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51227,b51222);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51227,b51222);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51227,b51223);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51227,b51223);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51227,b51224);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51227,b51224);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51227,b51225);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51227,b51225);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51227,b51226);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51227,b51226);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51227,b51227);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51227,b51227);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51227,b51228);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51227,b51228);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51227,b51229);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51227,b51229);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51227,b51230);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51227,b51230);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51227,b51231);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51227,b51231);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51227,b51232);

	D2_8 = _mm512_madd52lo_epu64(D2_8,a51228,b51220);
	D2_9 = _mm512_madd52hi_epu64(D2_9,a51228,b51220);
	D2_9 = _mm512_madd52lo_epu64(D2_9,a51228,b51221);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51228,b51221);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51228,b51222);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51228,b51222);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51228,b51223);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51228,b51223);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51228,b51224);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51228,b51224);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51228,b51225);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51228,b51225);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51228,b51226);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51228,b51226);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51228,b51227);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51228,b51227);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51228,b51228);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51228,b51228);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51228,b51229);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51228,b51229);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51228,b51230);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51228,b51230);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51228,b51231);

	D2_9 = _mm512_madd52lo_epu64(D2_9,a51229,b51220);
	D2_10 = _mm512_madd52hi_epu64(D2_10,a51229,b51220);
	D2_10 = _mm512_madd52lo_epu64(D2_10,a51229,b51221);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51229,b51221);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51229,b51222);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51229,b51222);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51229,b51223);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51229,b51223);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51229,b51224);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51229,b51224);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51229,b51225);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51229,b51225);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51229,b51226);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51229,b51226);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51229,b51227);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51229,b51227);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51229,b51228);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51229,b51228);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51229,b51229);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51229,b51229);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51229,b51230);

	D2_10 = _mm512_madd52lo_epu64(D2_10,a51230,b51220);
	D2_11 = _mm512_madd52hi_epu64(D2_11,a51230,b51220);
	D2_11 = _mm512_madd52lo_epu64(D2_11,a51230,b51221);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51230,b51221);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51230,b51222);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51230,b51222);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51230,b51223);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51230,b51223);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51230,b51224);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51230,b51224);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51230,b51225);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51230,b51225);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51230,b51226);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51230,b51226);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51230,b51227);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51230,b51227);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51230,b51228);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51230,b51228);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51230,b51229);

	D2_11 = _mm512_madd52lo_epu64(D2_11,a51231,b51220);
	D2_12 = _mm512_madd52hi_epu64(D2_12,a51231,b51220);
	D2_12 = _mm512_madd52lo_epu64(D2_12,a51231,b51221);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51231,b51221);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51231,b51222);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51231,b51222);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51231,b51223);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51231,b51223);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51231,b51224);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51231,b51224);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51231,b51225);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51231,b51225);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51231,b51226);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51231,b51226);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51231,b51227);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51231,b51227);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51231,b51228);

	D2_12 = _mm512_madd52lo_epu64(D2_12,a51232,b51220);
	D2_13 = _mm512_madd52hi_epu64(D2_13,a51232,b51220);
	D2_13 = _mm512_madd52lo_epu64(D2_13,a51232,b51221);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51232,b51221);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51232,b51222);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51232,b51222);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51232,b51223);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51232,b51223);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51232,b51224);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51232,b51224);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51232,b51225);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51232,b51225);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51232,b51226);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51232,b51226);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51232,b51227);

	D2_13 = _mm512_madd52lo_epu64(D2_13,a51233,b51220);
	D2_14 = _mm512_madd52hi_epu64(D2_14,a51233,b51220);
	D2_14 = _mm512_madd52lo_epu64(D2_14,a51233,b51221);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51233,b51221);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51233,b51222);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51233,b51222);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51233,b51223);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51233,b51223);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51233,b51224);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51233,b51224);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51233,b51225);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51233,b51225);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51233,b51226);

	D2_14 = _mm512_madd52lo_epu64(D2_14,a51234,b51220);
	D2_15 = _mm512_madd52hi_epu64(D2_15,a51234,b51220);
	D2_15 = _mm512_madd52lo_epu64(D2_15,a51234,b51221);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51234,b51221);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51234,b51222);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51234,b51222);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51234,b51223);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51234,b51223);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51234,b51224);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51234,b51224);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51234,b51225);

	D2_15 = _mm512_madd52lo_epu64(D2_15,a51235,b51220);
	D2_16 = _mm512_madd52hi_epu64(D2_16,a51235,b51220);
	D2_16 = _mm512_madd52lo_epu64(D2_16,a51235,b51221);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51235,b51221);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51235,b51222);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51235,b51222);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51235,b51223);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51235,b51223);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51235,b51224);

	D2_16 = _mm512_madd52lo_epu64(D2_16,a51236,b51220);
	D2_17 = _mm512_madd52hi_epu64(D2_17,a51236,b51220);
	D2_17 = _mm512_madd52lo_epu64(D2_17,a51236,b51221);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51236,b51221);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51236,b51222);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51236,b51222);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51236,b51223);

	D2_17 = _mm512_madd52lo_epu64(D2_17,a51237,b51220);
	D2_18 = _mm512_madd52hi_epu64(D2_18,a51237,b51220);
	D2_18 = _mm512_madd52lo_epu64(D2_18,a51237,b51221);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51237,b51221);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51237,b51222);

	D2_18 = _mm512_madd52lo_epu64(D2_18,a51238,b51220);
	D2_19 = _mm512_madd52hi_epu64(D2_19,a51238,b51220);
	D2_19 = _mm512_madd52lo_epu64(D2_19,a51238,b51221);

	D2_19 = _mm512_madd52lo_epu64(D2_19,a51239,b51220);


	// Carry management

	carry  = _mm512_srli_epi64(D2_1,52);
	D2_2 = _mm512_add_epi64(D2_2,carry);
	D2_1 = _mm512_and_si512(D2_1,mask52);
	carry  = _mm512_srli_epi64(D2_2,52);
	D2_3 = _mm512_add_epi64(D2_3,carry);
	D2_2 = _mm512_and_si512(D2_2,mask52);
	carry  = _mm512_srli_epi64(D2_3,52);
	D2_4 = _mm512_add_epi64(D2_4,carry);
	D2_3 = _mm512_and_si512(D2_3,mask52);
	carry  = _mm512_srli_epi64(D2_4,52);
	D2_5 = _mm512_add_epi64(D2_5,carry);
	D2_4 = _mm512_and_si512(D2_4,mask52);
	carry  = _mm512_srli_epi64(D2_5,52);
	D2_6 = _mm512_add_epi64(D2_6,carry);
	D2_5 = _mm512_and_si512(D2_5,mask52);
	carry  = _mm512_srli_epi64(D2_6,52);
	D2_7 = _mm512_add_epi64(D2_7,carry);
	D2_6 = _mm512_and_si512(D2_6,mask52);
	carry  = _mm512_srli_epi64(D2_7,52);
	D2_8 = _mm512_add_epi64(D2_8,carry);
	D2_7 = _mm512_and_si512(D2_7,mask52);
	carry  = _mm512_srli_epi64(D2_8,52);
	D2_9 = _mm512_add_epi64(D2_9,carry);
	D2_8 = _mm512_and_si512(D2_8,mask52);
	carry  = _mm512_srli_epi64(D2_9,52);
	D2_10 = _mm512_add_epi64(D2_10,carry);
	D2_9 = _mm512_and_si512(D2_9,mask52);
	carry  = _mm512_srli_epi64(D2_10,52);
	D2_11 = _mm512_add_epi64(D2_11,carry);
	D2_10 = _mm512_and_si512(D2_10,mask52);
	carry  = _mm512_srli_epi64(D2_11,52);
	D2_12 = _mm512_add_epi64(D2_12,carry);
	D2_11 = _mm512_and_si512(D2_11,mask52);
	carry  = _mm512_srli_epi64(D2_12,52);
	D2_13 = _mm512_add_epi64(D2_13,carry);
	D2_12 = _mm512_and_si512(D2_12,mask52);
	carry  = _mm512_srli_epi64(D2_13,52);
	D2_14 = _mm512_add_epi64(D2_14,carry);
	D2_13 = _mm512_and_si512(D2_13,mask52);
	carry  = _mm512_srli_epi64(D2_14,52);
	D2_15 = _mm512_add_epi64(D2_15,carry);
	D2_14 = _mm512_and_si512(D2_14,mask52);
	carry  = _mm512_srli_epi64(D2_15,52);
	D2_16 = _mm512_add_epi64(D2_16,carry);
	D2_15 = _mm512_and_si512(D2_15,mask52);
	carry  = _mm512_srli_epi64(D2_16,52);
	D2_17 = _mm512_add_epi64(D2_17,carry);
	D2_16 = _mm512_and_si512(D2_16,mask52);
	carry  = _mm512_srli_epi64(D2_17,52);
	D2_18 = _mm512_add_epi64(D2_18,carry);
	D2_17 = _mm512_and_si512(D2_17,mask52);
	carry  = _mm512_srli_epi64(D2_18,52);
	D2_19 = _mm512_add_epi64(D2_19,carry);
	D2_18 = _mm512_and_si512(D2_18,mask52);

	// D1 = (Al+Ah)*(Bl+Bh)

	__m512i D1_0;
	__m512i D1_1;
	__m512i D1_2;
	__m512i D1_3;
	__m512i D1_4;
	__m512i D1_5;
	__m512i D1_6;
	__m512i D1_7;
	__m512i D1_8;
	__m512i D1_9;
	__m512i D1_10;
	__m512i D1_11;
	__m512i D1_12;
	__m512i D1_13;
	__m512i D1_14;
	__m512i D1_15;
	__m512i D1_16;
	__m512i D1_17;
	__m512i D1_18;
	__m512i D1_19;

	__m512i alpah0 = _mm512_add_epi64(a5120,a51220);
	carry = alpah0>>52;
	alpah0 &= mask52;
	__m512i alpah1 = _mm512_add_epi64(a5121,carry);
	alpah1 = _mm512_add_epi64(alpah1,a51221);
	carry = alpah1>>52;
	alpah1 &= mask52;
	__m512i alpah2 = _mm512_add_epi64(a5122,carry);
	alpah2 = _mm512_add_epi64(alpah2,a51222);
	carry = alpah2>>52;
	alpah2 &= mask52;
	__m512i alpah3 = _mm512_add_epi64(a5123,carry);
	alpah3 = _mm512_add_epi64(alpah3,a51223);
	carry = alpah3>>52;
	alpah3 &= mask52;
	__m512i alpah4 = _mm512_add_epi64(a5124,carry);
	alpah4 = _mm512_add_epi64(alpah4,a51224);
	carry = alpah4>>52;
	alpah4 &= mask52;
	__m512i alpah5 = _mm512_add_epi64(a5125,carry);
	alpah5 = _mm512_add_epi64(alpah5,a51225);
	carry = alpah5>>52;
	alpah5 &= mask52;
	__m512i alpah6 = _mm512_add_epi64(a5126,carry);
	alpah6 = _mm512_add_epi64(alpah6,a51226);
	carry = alpah6>>52;
	alpah6 &= mask52;
	__m512i alpah7 = _mm512_add_epi64(a5127,carry);
	alpah7 = _mm512_add_epi64(alpah7,a51227);
	carry = alpah7>>52;
	alpah7 &= mask52;
	__m512i alpah8 = _mm512_add_epi64(a5128,carry);
	alpah8 = _mm512_add_epi64(alpah8,a51228);
	carry = alpah8>>52;
	alpah8 &= mask52;
	__m512i alpah9 = _mm512_add_epi64(a5129,carry);
	alpah9 = _mm512_add_epi64(alpah9,a51229);
	carry = alpah9>>52;
	alpah9 &= mask52;
	__m512i alpah10 = _mm512_add_epi64(a51210,carry);
	alpah10 = _mm512_add_epi64(alpah10,a51230);
	carry = alpah10>>52;
	alpah10 &= mask52;
	__m512i alpah11 = _mm512_add_epi64(a51211,carry);
	alpah11 = _mm512_add_epi64(alpah11,a51231);
	carry = alpah11>>52;
	alpah11 &= mask52;
	__m512i alpah12 = _mm512_add_epi64(a51212,carry);
	alpah12 = _mm512_add_epi64(alpah12,a51232);
	carry = alpah12>>52;
	alpah12 &= mask52;
	__m512i alpah13 = _mm512_add_epi64(a51213,carry);
	alpah13 = _mm512_add_epi64(alpah13,a51233);
	carry = alpah13>>52;
	alpah13 &= mask52;
	__m512i alpah14 = _mm512_add_epi64(a51214,carry);
	alpah14 = _mm512_add_epi64(alpah14,a51234);
	carry = alpah14>>52;
	alpah14 &= mask52;
	__m512i alpah15 = _mm512_add_epi64(a51215,carry);
	alpah15 = _mm512_add_epi64(alpah15,a51235);
	carry = alpah15>>52;
	alpah15 &= mask52;
	__m512i alpah16 = _mm512_add_epi64(a51216,carry);
	alpah16 = _mm512_add_epi64(alpah16,a51236);
	carry = alpah16>>52;
	alpah16 &= mask52;
	__m512i alpah17 = _mm512_add_epi64(a51217,carry);
	alpah17 = _mm512_add_epi64(alpah17,a51237);
	carry = alpah17>>52;
	alpah17 &= mask52;
	__m512i alpah18 = _mm512_add_epi64(a51218,carry);
	alpah18 = _mm512_add_epi64(alpah18,a51238);
	carry = alpah18>>52;
	alpah18 &= mask52;
	__m512i alpah19 = _mm512_add_epi64(a51219,carry);
	alpah19 = _mm512_add_epi64(alpah19,a51239);
	carry = alpah19>>52;
	alpah19 &= mask52;
	__m512i blpbh0 = _mm512_add_epi64(b5120,b51220);
	carry = blpbh0>>52;
	blpbh0 &= mask52;
	__m512i blpbh1 = _mm512_add_epi64(b5121,carry);
	blpbh1 = _mm512_add_epi64(blpbh1,b51221);
	carry = blpbh1>>52;
	blpbh1 &= mask52;
	__m512i blpbh2 = _mm512_add_epi64(b5122,carry);
	blpbh2 = _mm512_add_epi64(blpbh2,b51222);
	carry = blpbh2>>52;
	blpbh2 &= mask52;
	__m512i blpbh3 = _mm512_add_epi64(b5123,carry);
	blpbh3 = _mm512_add_epi64(blpbh3,b51223);
	carry = blpbh3>>52;
	blpbh3 &= mask52;
	__m512i blpbh4 = _mm512_add_epi64(b5124,carry);
	blpbh4 = _mm512_add_epi64(blpbh4,b51224);
	carry = blpbh4>>52;
	blpbh4 &= mask52;
	__m512i blpbh5 = _mm512_add_epi64(b5125,carry);
	blpbh5 = _mm512_add_epi64(blpbh5,b51225);
	carry = blpbh5>>52;
	blpbh5 &= mask52;
	__m512i blpbh6 = _mm512_add_epi64(b5126,carry);
	blpbh6 = _mm512_add_epi64(blpbh6,b51226);
	carry = blpbh6>>52;
	blpbh6 &= mask52;
	__m512i blpbh7 = _mm512_add_epi64(b5127,carry);
	blpbh7 = _mm512_add_epi64(blpbh7,b51227);
	carry = blpbh7>>52;
	blpbh7 &= mask52;
	__m512i blpbh8 = _mm512_add_epi64(b5128,carry);
	blpbh8 = _mm512_add_epi64(blpbh8,b51228);
	carry = blpbh8>>52;
	blpbh8 &= mask52;
	__m512i blpbh9 = _mm512_add_epi64(b5129,carry);
	blpbh9 = _mm512_add_epi64(blpbh9,b51229);
	carry = blpbh9>>52;
	blpbh9 &= mask52;
	__m512i blpbh10 = _mm512_add_epi64(b51210,carry);
	blpbh10 = _mm512_add_epi64(blpbh10,b51230);
	carry = blpbh10>>52;
	blpbh10 &= mask52;
	__m512i blpbh11 = _mm512_add_epi64(b51211,carry);
	blpbh11 = _mm512_add_epi64(blpbh11,b51231);
	carry = blpbh11>>52;
	blpbh11 &= mask52;
	__m512i blpbh12 = _mm512_add_epi64(b51212,carry);
	blpbh12 = _mm512_add_epi64(blpbh12,b51232);
	carry = blpbh12>>52;
	blpbh12 &= mask52;
	__m512i blpbh13 = _mm512_add_epi64(b51213,carry);
	blpbh13 = _mm512_add_epi64(blpbh13,b51233);
	carry = blpbh13>>52;
	blpbh13 &= mask52;
	__m512i blpbh14 = _mm512_add_epi64(b51214,carry);
	blpbh14 = _mm512_add_epi64(blpbh14,b51234);
	carry = blpbh14>>52;
	blpbh14 &= mask52;
	__m512i blpbh15 = _mm512_add_epi64(b51215,carry);
	blpbh15 = _mm512_add_epi64(blpbh15,b51235);
	carry = blpbh15>>52;
	blpbh15 &= mask52;
	__m512i blpbh16 = _mm512_add_epi64(b51216,carry);
	blpbh16 = _mm512_add_epi64(blpbh16,b51236);
	carry = blpbh16>>52;
	blpbh16 &= mask52;
	__m512i blpbh17 = _mm512_add_epi64(b51217,carry);
	blpbh17 = _mm512_add_epi64(blpbh17,b51237);
	carry = blpbh17>>52;
	blpbh17 &= mask52;
	__m512i blpbh18 = _mm512_add_epi64(b51218,carry);
	blpbh18 = _mm512_add_epi64(blpbh18,b51238);
	carry = blpbh18>>52;
	blpbh18 &= mask52;
	__m512i blpbh19 = _mm512_add_epi64(b51219,carry);
	blpbh19 = _mm512_add_epi64(blpbh19,b51239);
	carry = blpbh19>>52;
	blpbh19 &= mask52;
	D1_0 = _mm512_madd52lo_epu64(D0_20,alpah0,blpbh0);
	D1_1 = _mm512_madd52hi_epu64(D0_21,alpah0,blpbh0);
	D1_1 = _mm512_madd52lo_epu64(D1_1,alpah0,blpbh1);
	D1_2 = _mm512_madd52hi_epu64(D0_22,alpah0,blpbh1);
	D1_2 = _mm512_madd52lo_epu64(D1_2,alpah0,blpbh2);
	D1_3 = _mm512_madd52hi_epu64(D0_23,alpah0,blpbh2);
	D1_3 = _mm512_madd52lo_epu64(D1_3,alpah0,blpbh3);
	D1_4 = _mm512_madd52hi_epu64(D0_24,alpah0,blpbh3);
	D1_4 = _mm512_madd52lo_epu64(D1_4,alpah0,blpbh4);
	D1_5 = _mm512_madd52hi_epu64(D0_25,alpah0,blpbh4);
	D1_5 = _mm512_madd52lo_epu64(D1_5,alpah0,blpbh5);
	D1_6 = _mm512_madd52hi_epu64(D0_26,alpah0,blpbh5);
	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah0,blpbh6);
	D1_7 = _mm512_madd52hi_epu64(D0_27,alpah0,blpbh6);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah0,blpbh7);
	D1_8 = _mm512_madd52hi_epu64(D0_28,alpah0,blpbh7);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah0,blpbh8);
	D1_9 = _mm512_madd52hi_epu64(D0_29,alpah0,blpbh8);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah0,blpbh9);
	D1_10 = _mm512_madd52hi_epu64(D0_30,alpah0,blpbh9);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah0,blpbh10);
	D1_11 = _mm512_madd52hi_epu64(D0_31,alpah0,blpbh10);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah0,blpbh11);
	D1_12 = _mm512_madd52hi_epu64(D0_32,alpah0,blpbh11);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah0,blpbh12);
	D1_13 = _mm512_madd52hi_epu64(D0_33,alpah0,blpbh12);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah0,blpbh13);
	D1_14 = _mm512_madd52hi_epu64(D0_34,alpah0,blpbh13);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah0,blpbh14);
	D1_15 = _mm512_madd52hi_epu64(D0_35,alpah0,blpbh14);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah0,blpbh15);
	D1_16 = _mm512_madd52hi_epu64(D0_36,alpah0,blpbh15);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah0,blpbh16);
	D1_17 = _mm512_madd52hi_epu64(D0_37,alpah0,blpbh16);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah0,blpbh17);
	D1_18 = _mm512_madd52hi_epu64(D0_38,alpah0,blpbh17);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah0,blpbh18);
	D1_19 = _mm512_madd52hi_epu64(D0_39,alpah0,blpbh18);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah0,blpbh19);

	D1_1 = _mm512_madd52lo_epu64(D1_1,alpah1,blpbh0);
	D1_2 = _mm512_madd52hi_epu64(D1_2,alpah1,blpbh0);
	D1_2 = _mm512_madd52lo_epu64(D1_2,alpah1,blpbh1);
	D1_3 = _mm512_madd52hi_epu64(D1_3,alpah1,blpbh1);
	D1_3 = _mm512_madd52lo_epu64(D1_3,alpah1,blpbh2);
	D1_4 = _mm512_madd52hi_epu64(D1_4,alpah1,blpbh2);
	D1_4 = _mm512_madd52lo_epu64(D1_4,alpah1,blpbh3);
	D1_5 = _mm512_madd52hi_epu64(D1_5,alpah1,blpbh3);
	D1_5 = _mm512_madd52lo_epu64(D1_5,alpah1,blpbh4);
	D1_6 = _mm512_madd52hi_epu64(D1_6,alpah1,blpbh4);
	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah1,blpbh5);
	D1_7 = _mm512_madd52hi_epu64(D1_7,alpah1,blpbh5);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah1,blpbh6);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah1,blpbh6);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah1,blpbh7);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah1,blpbh7);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah1,blpbh8);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah1,blpbh8);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah1,blpbh9);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah1,blpbh9);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah1,blpbh10);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah1,blpbh10);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah1,blpbh11);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah1,blpbh11);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah1,blpbh12);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah1,blpbh12);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah1,blpbh13);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah1,blpbh13);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah1,blpbh14);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah1,blpbh14);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah1,blpbh15);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah1,blpbh15);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah1,blpbh16);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah1,blpbh16);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah1,blpbh17);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah1,blpbh17);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah1,blpbh18);

	D1_2 = _mm512_madd52lo_epu64(D1_2,alpah2,blpbh0);
	D1_3 = _mm512_madd52hi_epu64(D1_3,alpah2,blpbh0);
	D1_3 = _mm512_madd52lo_epu64(D1_3,alpah2,blpbh1);
	D1_4 = _mm512_madd52hi_epu64(D1_4,alpah2,blpbh1);
	D1_4 = _mm512_madd52lo_epu64(D1_4,alpah2,blpbh2);
	D1_5 = _mm512_madd52hi_epu64(D1_5,alpah2,blpbh2);
	D1_5 = _mm512_madd52lo_epu64(D1_5,alpah2,blpbh3);
	D1_6 = _mm512_madd52hi_epu64(D1_6,alpah2,blpbh3);
	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah2,blpbh4);
	D1_7 = _mm512_madd52hi_epu64(D1_7,alpah2,blpbh4);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah2,blpbh5);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah2,blpbh5);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah2,blpbh6);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah2,blpbh6);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah2,blpbh7);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah2,blpbh7);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah2,blpbh8);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah2,blpbh8);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah2,blpbh9);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah2,blpbh9);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah2,blpbh10);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah2,blpbh10);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah2,blpbh11);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah2,blpbh11);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah2,blpbh12);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah2,blpbh12);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah2,blpbh13);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah2,blpbh13);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah2,blpbh14);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah2,blpbh14);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah2,blpbh15);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah2,blpbh15);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah2,blpbh16);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah2,blpbh16);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah2,blpbh17);

	D1_3 = _mm512_madd52lo_epu64(D1_3,alpah3,blpbh0);
	D1_4 = _mm512_madd52hi_epu64(D1_4,alpah3,blpbh0);
	D1_4 = _mm512_madd52lo_epu64(D1_4,alpah3,blpbh1);
	D1_5 = _mm512_madd52hi_epu64(D1_5,alpah3,blpbh1);
	D1_5 = _mm512_madd52lo_epu64(D1_5,alpah3,blpbh2);
	D1_6 = _mm512_madd52hi_epu64(D1_6,alpah3,blpbh2);
	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah3,blpbh3);
	D1_7 = _mm512_madd52hi_epu64(D1_7,alpah3,blpbh3);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah3,blpbh4);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah3,blpbh4);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah3,blpbh5);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah3,blpbh5);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah3,blpbh6);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah3,blpbh6);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah3,blpbh7);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah3,blpbh7);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah3,blpbh8);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah3,blpbh8);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah3,blpbh9);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah3,blpbh9);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah3,blpbh10);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah3,blpbh10);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah3,blpbh11);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah3,blpbh11);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah3,blpbh12);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah3,blpbh12);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah3,blpbh13);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah3,blpbh13);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah3,blpbh14);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah3,blpbh14);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah3,blpbh15);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah3,blpbh15);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah3,blpbh16);

	D1_4 = _mm512_madd52lo_epu64(D1_4,alpah4,blpbh0);
	D1_5 = _mm512_madd52hi_epu64(D1_5,alpah4,blpbh0);
	D1_5 = _mm512_madd52lo_epu64(D1_5,alpah4,blpbh1);
	D1_6 = _mm512_madd52hi_epu64(D1_6,alpah4,blpbh1);
	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah4,blpbh2);
	D1_7 = _mm512_madd52hi_epu64(D1_7,alpah4,blpbh2);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah4,blpbh3);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah4,blpbh3);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah4,blpbh4);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah4,blpbh4);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah4,blpbh5);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah4,blpbh5);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah4,blpbh6);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah4,blpbh6);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah4,blpbh7);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah4,blpbh7);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah4,blpbh8);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah4,blpbh8);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah4,blpbh9);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah4,blpbh9);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah4,blpbh10);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah4,blpbh10);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah4,blpbh11);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah4,blpbh11);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah4,blpbh12);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah4,blpbh12);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah4,blpbh13);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah4,blpbh13);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah4,blpbh14);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah4,blpbh14);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah4,blpbh15);

	D1_5 = _mm512_madd52lo_epu64(D1_5,alpah5,blpbh0);
	D1_6 = _mm512_madd52hi_epu64(D1_6,alpah5,blpbh0);
	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah5,blpbh1);
	D1_7 = _mm512_madd52hi_epu64(D1_7,alpah5,blpbh1);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah5,blpbh2);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah5,blpbh2);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah5,blpbh3);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah5,blpbh3);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah5,blpbh4);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah5,blpbh4);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah5,blpbh5);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah5,blpbh5);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah5,blpbh6);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah5,blpbh6);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah5,blpbh7);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah5,blpbh7);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah5,blpbh8);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah5,blpbh8);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah5,blpbh9);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah5,blpbh9);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah5,blpbh10);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah5,blpbh10);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah5,blpbh11);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah5,blpbh11);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah5,blpbh12);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah5,blpbh12);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah5,blpbh13);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah5,blpbh13);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah5,blpbh14);

	D1_6 = _mm512_madd52lo_epu64(D1_6,alpah6,blpbh0);
	D1_7 = _mm512_madd52hi_epu64(D1_7,alpah6,blpbh0);
	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah6,blpbh1);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah6,blpbh1);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah6,blpbh2);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah6,blpbh2);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah6,blpbh3);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah6,blpbh3);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah6,blpbh4);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah6,blpbh4);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah6,blpbh5);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah6,blpbh5);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah6,blpbh6);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah6,blpbh6);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah6,blpbh7);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah6,blpbh7);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah6,blpbh8);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah6,blpbh8);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah6,blpbh9);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah6,blpbh9);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah6,blpbh10);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah6,blpbh10);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah6,blpbh11);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah6,blpbh11);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah6,blpbh12);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah6,blpbh12);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah6,blpbh13);

	D1_7 = _mm512_madd52lo_epu64(D1_7,alpah7,blpbh0);
	D1_8 = _mm512_madd52hi_epu64(D1_8,alpah7,blpbh0);
	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah7,blpbh1);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah7,blpbh1);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah7,blpbh2);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah7,blpbh2);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah7,blpbh3);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah7,blpbh3);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah7,blpbh4);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah7,blpbh4);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah7,blpbh5);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah7,blpbh5);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah7,blpbh6);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah7,blpbh6);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah7,blpbh7);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah7,blpbh7);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah7,blpbh8);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah7,blpbh8);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah7,blpbh9);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah7,blpbh9);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah7,blpbh10);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah7,blpbh10);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah7,blpbh11);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah7,blpbh11);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah7,blpbh12);

	D1_8 = _mm512_madd52lo_epu64(D1_8,alpah8,blpbh0);
	D1_9 = _mm512_madd52hi_epu64(D1_9,alpah8,blpbh0);
	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah8,blpbh1);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah8,blpbh1);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah8,blpbh2);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah8,blpbh2);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah8,blpbh3);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah8,blpbh3);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah8,blpbh4);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah8,blpbh4);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah8,blpbh5);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah8,blpbh5);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah8,blpbh6);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah8,blpbh6);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah8,blpbh7);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah8,blpbh7);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah8,blpbh8);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah8,blpbh8);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah8,blpbh9);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah8,blpbh9);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah8,blpbh10);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah8,blpbh10);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah8,blpbh11);

	D1_9 = _mm512_madd52lo_epu64(D1_9,alpah9,blpbh0);
	D1_10 = _mm512_madd52hi_epu64(D1_10,alpah9,blpbh0);
	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah9,blpbh1);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah9,blpbh1);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah9,blpbh2);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah9,blpbh2);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah9,blpbh3);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah9,blpbh3);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah9,blpbh4);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah9,blpbh4);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah9,blpbh5);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah9,blpbh5);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah9,blpbh6);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah9,blpbh6);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah9,blpbh7);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah9,blpbh7);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah9,blpbh8);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah9,blpbh8);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah9,blpbh9);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah9,blpbh9);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah9,blpbh10);

	D1_10 = _mm512_madd52lo_epu64(D1_10,alpah10,blpbh0);
	D1_11 = _mm512_madd52hi_epu64(D1_11,alpah10,blpbh0);
	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah10,blpbh1);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah10,blpbh1);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah10,blpbh2);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah10,blpbh2);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah10,blpbh3);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah10,blpbh3);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah10,blpbh4);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah10,blpbh4);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah10,blpbh5);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah10,blpbh5);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah10,blpbh6);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah10,blpbh6);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah10,blpbh7);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah10,blpbh7);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah10,blpbh8);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah10,blpbh8);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah10,blpbh9);

	D1_11 = _mm512_madd52lo_epu64(D1_11,alpah11,blpbh0);
	D1_12 = _mm512_madd52hi_epu64(D1_12,alpah11,blpbh0);
	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah11,blpbh1);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah11,blpbh1);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah11,blpbh2);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah11,blpbh2);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah11,blpbh3);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah11,blpbh3);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah11,blpbh4);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah11,blpbh4);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah11,blpbh5);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah11,blpbh5);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah11,blpbh6);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah11,blpbh6);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah11,blpbh7);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah11,blpbh7);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah11,blpbh8);

	D1_12 = _mm512_madd52lo_epu64(D1_12,alpah12,blpbh0);
	D1_13 = _mm512_madd52hi_epu64(D1_13,alpah12,blpbh0);
	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah12,blpbh1);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah12,blpbh1);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah12,blpbh2);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah12,blpbh2);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah12,blpbh3);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah12,blpbh3);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah12,blpbh4);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah12,blpbh4);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah12,blpbh5);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah12,blpbh5);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah12,blpbh6);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah12,blpbh6);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah12,blpbh7);

	D1_13 = _mm512_madd52lo_epu64(D1_13,alpah13,blpbh0);
	D1_14 = _mm512_madd52hi_epu64(D1_14,alpah13,blpbh0);
	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah13,blpbh1);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah13,blpbh1);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah13,blpbh2);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah13,blpbh2);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah13,blpbh3);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah13,blpbh3);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah13,blpbh4);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah13,blpbh4);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah13,blpbh5);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah13,blpbh5);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah13,blpbh6);

	D1_14 = _mm512_madd52lo_epu64(D1_14,alpah14,blpbh0);
	D1_15 = _mm512_madd52hi_epu64(D1_15,alpah14,blpbh0);
	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah14,blpbh1);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah14,blpbh1);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah14,blpbh2);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah14,blpbh2);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah14,blpbh3);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah14,blpbh3);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah14,blpbh4);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah14,blpbh4);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah14,blpbh5);

	D1_15 = _mm512_madd52lo_epu64(D1_15,alpah15,blpbh0);
	D1_16 = _mm512_madd52hi_epu64(D1_16,alpah15,blpbh0);
	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah15,blpbh1);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah15,blpbh1);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah15,blpbh2);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah15,blpbh2);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah15,blpbh3);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah15,blpbh3);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah15,blpbh4);

	D1_16 = _mm512_madd52lo_epu64(D1_16,alpah16,blpbh0);
	D1_17 = _mm512_madd52hi_epu64(D1_17,alpah16,blpbh0);
	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah16,blpbh1);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah16,blpbh1);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah16,blpbh2);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah16,blpbh2);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah16,blpbh3);

	D1_17 = _mm512_madd52lo_epu64(D1_17,alpah17,blpbh0);
	D1_18 = _mm512_madd52hi_epu64(D1_18,alpah17,blpbh0);
	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah17,blpbh1);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah17,blpbh1);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah17,blpbh2);

	D1_18 = _mm512_madd52lo_epu64(D1_18,alpah18,blpbh0);
	D1_19 = _mm512_madd52hi_epu64(D1_19,alpah18,blpbh0);
	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah18,blpbh1);

	D1_19 = _mm512_madd52lo_epu64(D1_19,alpah19,blpbh0);


	// Carry management

	carry  = _mm512_srli_epi64(D1_0,52);
	D1_0 = _mm512_and_si512(D1_0,mask52);
	D1_1 = _mm512_add_epi64(D1_1,carry);
	carry  = _mm512_srli_epi64(D1_1,52);
	D1_2 = _mm512_add_epi64(D1_2,carry);
	D1_1 = _mm512_and_si512(D1_1,mask52);
	carry  = _mm512_srli_epi64(D1_2,52);
	D1_3 = _mm512_add_epi64(D1_3,carry);
	D1_2 = _mm512_and_si512(D1_2,mask52);
	carry  = _mm512_srli_epi64(D1_3,52);
	D1_4 = _mm512_add_epi64(D1_4,carry);
	D1_3 = _mm512_and_si512(D1_3,mask52);
	carry  = _mm512_srli_epi64(D1_4,52);
	D1_5 = _mm512_add_epi64(D1_5,carry);
	D1_4 = _mm512_and_si512(D1_4,mask52);
	carry  = _mm512_srli_epi64(D1_5,52);
	D1_6 = _mm512_add_epi64(D1_6,carry);
	D1_5 = _mm512_and_si512(D1_5,mask52);
	carry  = _mm512_srli_epi64(D1_6,52);
	D1_7 = _mm512_add_epi64(D1_7,carry);
	D1_6 = _mm512_and_si512(D1_6,mask52);
	carry  = _mm512_srli_epi64(D1_7,52);
	D1_8 = _mm512_add_epi64(D1_8,carry);
	D1_7 = _mm512_and_si512(D1_7,mask52);
	carry  = _mm512_srli_epi64(D1_8,52);
	D1_9 = _mm512_add_epi64(D1_9,carry);
	D1_8 = _mm512_and_si512(D1_8,mask52);
	carry  = _mm512_srli_epi64(D1_9,52);
	D1_10 = _mm512_add_epi64(D1_10,carry);
	D1_9 = _mm512_and_si512(D1_9,mask52);
	carry  = _mm512_srli_epi64(D1_10,52);
	D1_11 = _mm512_add_epi64(D1_11,carry);
	D1_10 = _mm512_and_si512(D1_10,mask52);
	carry  = _mm512_srli_epi64(D1_11,52);
	D1_12 = _mm512_add_epi64(D1_12,carry);
	D1_11 = _mm512_and_si512(D1_11,mask52);
	carry  = _mm512_srli_epi64(D1_12,52);
	D1_13 = _mm512_add_epi64(D1_13,carry);
	D1_12 = _mm512_and_si512(D1_12,mask52);
	carry  = _mm512_srli_epi64(D1_13,52);
	D1_14 = _mm512_add_epi64(D1_14,carry);
	D1_13 = _mm512_and_si512(D1_13,mask52);
	carry  = _mm512_srli_epi64(D1_14,52);
	D1_15 = _mm512_add_epi64(D1_15,carry);
	D1_14 = _mm512_and_si512(D1_14,mask52);
	carry  = _mm512_srli_epi64(D1_15,52);
	D1_16 = _mm512_add_epi64(D1_16,carry);
	D1_15 = _mm512_and_si512(D1_15,mask52);
	carry  = _mm512_srli_epi64(D1_16,52);
	D1_17 = _mm512_add_epi64(D1_17,carry);
	D1_16 = _mm512_and_si512(D1_16,mask52);
	carry  = _mm512_srli_epi64(D1_17,52);
	D1_18 = _mm512_add_epi64(D1_18,carry);
	D1_17 = _mm512_and_si512(D1_17,mask52);
	carry  = _mm512_srli_epi64(D1_18,52);
	D1_19 = _mm512_add_epi64(D1_19,carry);
	D1_18 = _mm512_and_si512(D1_18,mask52);

	// Final reconstruction


	// tmp = D0+D2, radix 2^1039

	__m512i tmp0 = _mm512_add_epi64(D0_0,D2_0);
	__m512i carry_tmp  = _mm512_srli_epi64(tmp0,52);
	tmp0 = _mm512_and_si512(tmp0,mask52);

	__m512i tmp1 = _mm512_add_epi64(D0_1,carry_tmp);
	tmp1 = _mm512_add_epi64(tmp1,D2_1);
	carry_tmp  = _mm512_srli_epi64(tmp1,52);
	tmp1 = _mm512_and_si512(tmp1,mask52);

	__m512i tmp2 = _mm512_add_epi64(D0_2,carry_tmp);
	tmp2 = _mm512_add_epi64(tmp2,D2_2);
	carry_tmp  = _mm512_srli_epi64(tmp2,52);
	tmp2 = _mm512_and_si512(tmp2,mask52);

	__m512i tmp3 = _mm512_add_epi64(D0_3,carry_tmp);
	tmp3 = _mm512_add_epi64(tmp3,D2_3);
	carry_tmp  = _mm512_srli_epi64(tmp3,52);
	tmp3 = _mm512_and_si512(tmp3,mask52);

	__m512i tmp4 = _mm512_add_epi64(D0_4,carry_tmp);
	tmp4 = _mm512_add_epi64(tmp4,D2_4);
	carry_tmp  = _mm512_srli_epi64(tmp4,52);
	tmp4 = _mm512_and_si512(tmp4,mask52);

	__m512i tmp5 = _mm512_add_epi64(D0_5,carry_tmp);
	tmp5 = _mm512_add_epi64(tmp5,D2_5);
	carry_tmp  = _mm512_srli_epi64(tmp5,52);
	tmp5 = _mm512_and_si512(tmp5,mask52);

	__m512i tmp6 = _mm512_add_epi64(D0_6,carry_tmp);
	tmp6 = _mm512_add_epi64(tmp6,D2_6);
	carry_tmp  = _mm512_srli_epi64(tmp6,52);
	tmp6 = _mm512_and_si512(tmp6,mask52);

	__m512i tmp7 = _mm512_add_epi64(D0_7,carry_tmp);
	tmp7 = _mm512_add_epi64(tmp7,D2_7);
	carry_tmp  = _mm512_srli_epi64(tmp7,52);
	tmp7 = _mm512_and_si512(tmp7,mask52);

	__m512i tmp8 = _mm512_add_epi64(D0_8,carry_tmp);
	tmp8 = _mm512_add_epi64(tmp8,D2_8);
	carry_tmp  = _mm512_srli_epi64(tmp8,52);
	tmp8 = _mm512_and_si512(tmp8,mask52);

	__m512i tmp9 = _mm512_add_epi64(D0_9,carry_tmp);
	tmp9 = _mm512_add_epi64(tmp9,D2_9);
	carry_tmp  = _mm512_srli_epi64(tmp9,52);
	tmp9 = _mm512_and_si512(tmp9,mask52);

	__m512i tmp10 = _mm512_add_epi64(D0_10,carry_tmp);
	tmp10 = _mm512_add_epi64(tmp10,D2_10);
	carry_tmp  = _mm512_srli_epi64(tmp10,52);
	tmp10 = _mm512_and_si512(tmp10,mask52);

	__m512i tmp11 = _mm512_add_epi64(D0_11,carry_tmp);
	tmp11 = _mm512_add_epi64(tmp11,D2_11);
	carry_tmp  = _mm512_srli_epi64(tmp11,52);
	tmp11 = _mm512_and_si512(tmp11,mask52);

	__m512i tmp12 = _mm512_add_epi64(D0_12,carry_tmp);
	tmp12 = _mm512_add_epi64(tmp12,D2_12);
	carry_tmp  = _mm512_srli_epi64(tmp12,52);
	tmp12 = _mm512_and_si512(tmp12,mask52);

	__m512i tmp13 = _mm512_add_epi64(D0_13,carry_tmp);
	tmp13 = _mm512_add_epi64(tmp13,D2_13);
	carry_tmp  = _mm512_srli_epi64(tmp13,52);
	tmp13 = _mm512_and_si512(tmp13,mask52);

	__m512i tmp14 = _mm512_add_epi64(D0_14,carry_tmp);
	tmp14 = _mm512_add_epi64(tmp14,D2_14);
	carry_tmp  = _mm512_srli_epi64(tmp14,52);
	tmp14 = _mm512_and_si512(tmp14,mask52);

	__m512i tmp15 = _mm512_add_epi64(D0_15,carry_tmp);
	tmp15 = _mm512_add_epi64(tmp15,D2_15);
	carry_tmp  = _mm512_srli_epi64(tmp15,52);
	tmp15 = _mm512_and_si512(tmp15,mask52);

	__m512i tmp16 = _mm512_add_epi64(D0_16,carry_tmp);
	tmp16 = _mm512_add_epi64(tmp16,D2_16);
	carry_tmp  = _mm512_srli_epi64(tmp16,52);
	tmp16 = _mm512_and_si512(tmp16,mask52);

	__m512i tmp17 = _mm512_add_epi64(D0_17,carry_tmp);
	tmp17 = _mm512_add_epi64(tmp17,D2_17);
	carry_tmp  = _mm512_srli_epi64(tmp17,52);
	tmp17 = _mm512_and_si512(tmp17,mask52);

	__m512i tmp18 = _mm512_add_epi64(D0_18,carry_tmp);
	tmp18 = _mm512_add_epi64(tmp18,D2_18);
	carry_tmp  = _mm512_srli_epi64(tmp18,52);
	tmp18 = _mm512_and_si512(tmp18,mask52);

	__m512i tmp19 = _mm512_add_epi64(D0_19,carry_tmp);
	tmp19 = _mm512_add_epi64(tmp19,D2_19);
	carry_tmp  = _mm512_srli_epi64(tmp19,51);
	tmp19 = _mm512_and_si512(tmp19,mask51);// radix 2**1039


	// D1 = D1 -tmp, radix 2^1039

	D1_0 = _mm512_sub_epi64(D1_0,tmp0);
	__m512i borrow = _mm512_srli_epi64(D1_0,52)&un;
	D1_0 = _mm512_and_si512(D1_0,mask52);
	borrow = _mm512_add_epi64(tmp1,borrow);
	D1_1 = _mm512_sub_epi64(D1_1,borrow);
	borrow  = _mm512_srli_epi64(D1_1,52)&un;
	D1_1 = _mm512_and_si512(D1_1,mask52);

	borrow = _mm512_add_epi64(tmp2,borrow);
	D1_2 = _mm512_sub_epi64(D1_2,borrow);
	borrow  = _mm512_srli_epi64(D1_2,52)&un;
	D1_2 = _mm512_and_si512(D1_2,mask52);

	borrow = _mm512_add_epi64(tmp3,borrow);
	D1_3 = _mm512_sub_epi64(D1_3,borrow);
	borrow  = _mm512_srli_epi64(D1_3,52)&un;
	D1_3 = _mm512_and_si512(D1_3,mask52);

	borrow = _mm512_add_epi64(tmp4,borrow);
	D1_4 = _mm512_sub_epi64(D1_4,borrow);
	borrow  = _mm512_srli_epi64(D1_4,52)&un;
	D1_4 = _mm512_and_si512(D1_4,mask52);

	borrow = _mm512_add_epi64(tmp5,borrow);
	D1_5 = _mm512_sub_epi64(D1_5,borrow);
	borrow  = _mm512_srli_epi64(D1_5,52)&un;
	D1_5 = _mm512_and_si512(D1_5,mask52);

	borrow = _mm512_add_epi64(tmp6,borrow);
	D1_6 = _mm512_sub_epi64(D1_6,borrow);
	borrow  = _mm512_srli_epi64(D1_6,52)&un;
	D1_6 = _mm512_and_si512(D1_6,mask52);

	borrow = _mm512_add_epi64(tmp7,borrow);
	D1_7 = _mm512_sub_epi64(D1_7,borrow);
	borrow  = _mm512_srli_epi64(D1_7,52)&un;
	D1_7 = _mm512_and_si512(D1_7,mask52);

	borrow = _mm512_add_epi64(tmp8,borrow);
	D1_8 = _mm512_sub_epi64(D1_8,borrow);
	borrow  = _mm512_srli_epi64(D1_8,52)&un;
	D1_8 = _mm512_and_si512(D1_8,mask52);

	borrow = _mm512_add_epi64(tmp9,borrow);
	D1_9 = _mm512_sub_epi64(D1_9,borrow);
	borrow  = _mm512_srli_epi64(D1_9,52)&un;
	D1_9 = _mm512_and_si512(D1_9,mask52);

	borrow = _mm512_add_epi64(tmp10,borrow);
	D1_10 = _mm512_sub_epi64(D1_10,borrow);
	borrow  = _mm512_srli_epi64(D1_10,52)&un;
	D1_10 = _mm512_and_si512(D1_10,mask52);

	borrow = _mm512_add_epi64(tmp11,borrow);
	D1_11 = _mm512_sub_epi64(D1_11,borrow);
	borrow  = _mm512_srli_epi64(D1_11,52)&un;
	D1_11 = _mm512_and_si512(D1_11,mask52);

	borrow = _mm512_add_epi64(tmp12,borrow);
	D1_12 = _mm512_sub_epi64(D1_12,borrow);
	borrow  = _mm512_srli_epi64(D1_12,52)&un;
	D1_12 = _mm512_and_si512(D1_12,mask52);

	borrow = _mm512_add_epi64(tmp13,borrow);
	D1_13 = _mm512_sub_epi64(D1_13,borrow);
	borrow  = _mm512_srli_epi64(D1_13,52)&un;
	D1_13 = _mm512_and_si512(D1_13,mask52);

	borrow = _mm512_add_epi64(tmp14,borrow);
	D1_14 = _mm512_sub_epi64(D1_14,borrow);
	borrow  = _mm512_srli_epi64(D1_14,52)&un;
	D1_14 = _mm512_and_si512(D1_14,mask52);

	borrow = _mm512_add_epi64(tmp15,borrow);
	D1_15 = _mm512_sub_epi64(D1_15,borrow);
	borrow  = _mm512_srli_epi64(D1_15,52)&un;
	D1_15 = _mm512_and_si512(D1_15,mask52);

	borrow = _mm512_add_epi64(tmp16,borrow);
	D1_16 = _mm512_sub_epi64(D1_16,borrow);
	borrow  = _mm512_srli_epi64(D1_16,52)&un;
	D1_16 = _mm512_and_si512(D1_16,mask52);

	borrow = _mm512_add_epi64(tmp17,borrow);
	D1_17 = _mm512_sub_epi64(D1_17,borrow);
	borrow  = _mm512_srli_epi64(D1_17,52)&un;
	D1_17 = _mm512_and_si512(D1_17,mask52);

	borrow = _mm512_add_epi64(tmp18,borrow);
	D1_18 = _mm512_sub_epi64(D1_18,borrow);
	borrow  = _mm512_srli_epi64(D1_18,52)&un;
	D1_18 = _mm512_and_si512(D1_18,mask52);

	borrow = _mm512_add_epi64(tmp19,borrow);
	D1_19 = _mm512_sub_epi64(D1_19,borrow);
	borrow = _mm512_srli_epi64(D1_19,51)&un;
	D1_19 = _mm512_and_si512(D1_19,mask51);// radix 2**1039



	_mm512_store_epi64(out+0,D0_0);
	_mm512_store_epi64(out+1,D0_1);
	_mm512_store_epi64(out+2,D0_2);
	_mm512_store_epi64(out+3,D0_3);
	_mm512_store_epi64(out+4,D0_4);
	_mm512_store_epi64(out+5,D0_5);
	_mm512_store_epi64(out+6,D0_6);
	_mm512_store_epi64(out+7,D0_7);
	_mm512_store_epi64(out+8,D0_8);
	_mm512_store_epi64(out+9,D0_9);
	_mm512_store_epi64(out+10,D0_10);
	_mm512_store_epi64(out+11,D0_11);
	_mm512_store_epi64(out+12,D0_12);
	_mm512_store_epi64(out+13,D0_13);
	_mm512_store_epi64(out+14,D0_14);
	_mm512_store_epi64(out+15,D0_15);
	_mm512_store_epi64(out+16,D0_16);
	_mm512_store_epi64(out+17,D0_17);
	_mm512_store_epi64(out+18,D0_18);
	_mm512_store_epi64(out+19,D0_19);
	_mm512_store_epi64(out+20,D1_0);
	_mm512_store_epi64(out+21,D1_1);
	_mm512_store_epi64(out+22,D1_2);
	_mm512_store_epi64(out+23,D1_3);
	_mm512_store_epi64(out+24,D1_4);
	_mm512_store_epi64(out+25,D1_5);
	_mm512_store_epi64(out+26,D1_6);
	_mm512_store_epi64(out+27,D1_7);
	_mm512_store_epi64(out+28,D1_8);
	_mm512_store_epi64(out+29,D1_9);
	_mm512_store_epi64(out+30,D1_10);
	_mm512_store_epi64(out+31,D1_11);
	_mm512_store_epi64(out+32,D1_12);
	_mm512_store_epi64(out+33,D1_13);
	_mm512_store_epi64(out+34,D1_14);
	_mm512_store_epi64(out+35,D1_15);
	_mm512_store_epi64(out+36,D1_16);
	_mm512_store_epi64(out+37,D1_17);
	_mm512_store_epi64(out+38,D1_18);
	_mm512_store_epi64(out+39,D1_19);

}


/* Karatsuba multiplication */

static inline void force_inline mul512_8_4154KK_modM(__m512i out[80], __m512i a512[80], __m512i b512[80])
{

	__m512i D0[80], D1[40], D2[40], alpah[40], blpbh[40], alpahbis[40], blpbhbis[40];


	// al*bl, radix 2^1039 result
	
	mul512_8_2078K(D0, a512, b512);

	

	// ah*bh, radix 2^1039 result
	
	mul512_8_2078K_modM(D2, a512+40, b512+40);




	// ah*bh, radix 2^1039 result
	
	add512_8_2078K(alpah, a512, a512+40);
	
	add512_8_2078K(blpbh, b512, b512+40);
	
	mul512_8_2078K_modM(D1, alpah, blpbh);
	
	/*displayVect512_NB(a512,"a512",80);
	displayVect512_NB(b512,"b512",80);
	
	
	displayVect512_NB(alpah,"alpah",40);
	displayVect512_NB(blpbh,"blpbh",40);
	

	displayVect512_NB_COEFF(D1,"D1");
	
	//getchar();//*/
	
	/*unsigned long int a64[8][NB_COEFF64_SIZE_K], b64[8][NB_COEFF64_SIZE_K], res64[8][NB_COEFF64_SIZE_K*2], res_gmp[NB_COEFF64_SIZE_K*2];
	size_t countp;
	
	int counter=0,flag=0;
	
	fcontract_8_512_2077K(a64,alpah);
	fcontract_8_512_2077K(b64,blpbh);
	
	fexpand_8_512_2077K(alpahbis,a64);
	
	fexpand_8_512_2077K(blpbhbis,b64);
	
	displayVect512_NB(alpah,"alpah   ",40);
	displayVect512_NB(alpahbis,"alpahbis",40);
	getchar();
	displayVect512_NB(blpbh,"blpbh   ",40);
	displayVect512_NB(blpbhbis,"blpbhbis",40);
	//getchar();//*/
	
	
	
	/*mpz_t A, B, C;// UPB is used as upper bound
	
	mpz_inits (A, B, C, NULL);
	//conversion_8_r2077K(D1,D1);
	
	fcontract_8_512_2077K_res( res64, D1);
	for(int i=0;i<8;i++)
	{

		mpz_import(A, NB_COEFF64_SIZE_K, -1, sizeof(b64[0][0]) ,0,0, a64[i]);

		mpz_import(B, NB_COEFF64_SIZE_K, -1, sizeof(b64[0][0]) ,0,0, b64[i]);
		
		gmp_printf("A  : 0x%ZX\n\n\n", A);

		displayVect(a64[i],"a64",33);
		gmp_printf("B  : 0x%ZX\n\n\n", B);
		displayVect(b64[i],"b64",33);
		
		
	
	
		mpz_mul(C,A,B);
		mpz_export(res_gmp, &countp, -1, sizeof(b64[0][0]) ,0,0, C);
		displayVect(res_gmp, "res_gmp     ",NB_COEFF64_SIZE_K*2);
		displayVect(res64[i],"res64[i]    ",NB_COEFF64_SIZE_K*2);
		
		
		printf("xor = ");
		for(int j=0;j<NB_COEFF64_SIZE_K*2;j++){
			printf("%16.16lX ",res64[i][NB_COEFF64_SIZE_K*2-1-j]^res_gmp[NB_COEFF64_SIZE_K*2-1-j]);
		}
		printf("\n");

	//}
	//printf("\n");
	
	//for(int i=0;i<8;i++){//
		for(int j=0;j<NB_COEFF64_SIZE_K*2;j++)
			if(res64[i][j]^res_gmp[j]) flag++;
		flag?counter++,flag=0:counter,flag=0;
		printf("\n");
	}
	if(counter) printf("%d erreurs !\nToo bad !!!!!!!!!!!!!!!!!!!\n\n",counter),counter=0;
	else printf("Victory alpah*blbph !!!!!!!!!!!!!!!!!!!\n\n");
	counter=0;

	//}
	
	// conversion in radix 2^2077 conversion
	
	//displayVect512_NB_COEFF(D0,"D0");
	/*displayVect512_NB_COEFF(D0,"D0");

	getchar();//*/
	
	
	conversion_8_r2077K(D0,D0);
	/*conversion_8_r2077K(D1,D1);
	conversion_8_r2077K(D2,D2);//*/
	
	
	//__m512i c = 
	/*displayVect512_NB(D1,"D1",40);
	add512_8_2078K(D1, D1, D0+40);
	//D1[40] = _mm512_add_epi64(D1[40],c);
	displayVect512_NB(D0+40,"D0+40",40);
	displayVect512_NB(D1,"D1",40);
	
	// 	retenue
	__m512i c = _mm512_srli_epi64(D1[39],49);
	displayVect512(&c,"c");
	
	//getchar();
	
	D1[39] = _mm512_and_si512(D1[39],mask50);
	displayVect512_NB(D1,"D1",40);
	
	
	D1[40] = _mm512_add_epi64(D1[40],c);
	
	
	add512_8_2078K(D1+40, D1+40, D2);
	c = _mm512_srli_epi64(D1[79],49);
	D1[79] = _mm512_and_si512(D1[79],mask50);//*/
	
	
	__m512i D0_0 = _mm512_load_epi64(D0), D2_0 = _mm512_load_epi64(D2);
	__m512i D0_1 = _mm512_load_epi64(D0+1), D2_1 = _mm512_load_epi64(D2+1);
	__m512i D0_2 = _mm512_load_epi64(D0+2), D2_2 = _mm512_load_epi64(D2+2);
	__m512i D0_3 = _mm512_load_epi64(D0+3), D2_3 = _mm512_load_epi64(D2+3);
	__m512i D0_4 = _mm512_load_epi64(D0+4), D2_4 = _mm512_load_epi64(D2+4);
	__m512i D0_5 = _mm512_load_epi64(D0+5), D2_5 = _mm512_load_epi64(D2+5);
	__m512i D0_6 = _mm512_load_epi64(D0+6), D2_6 = _mm512_load_epi64(D2+6);
	__m512i D0_7 = _mm512_load_epi64(D0+7), D2_7 = _mm512_load_epi64(D2+7);
	__m512i D0_8 = _mm512_load_epi64(D0+8), D2_8 = _mm512_load_epi64(D2+8);
	__m512i D0_9 = _mm512_load_epi64(D0+9), D2_9 = _mm512_load_epi64(D2+9);
	__m512i D0_10 = _mm512_load_epi64(D0+10), D2_10 = _mm512_load_epi64(D2+10);
	__m512i D0_11 = _mm512_load_epi64(D0+11), D2_11 = _mm512_load_epi64(D2+11);
	__m512i D0_12 = _mm512_load_epi64(D0+12), D2_12 = _mm512_load_epi64(D2+12);
	__m512i D0_13 = _mm512_load_epi64(D0+13), D2_13 = _mm512_load_epi64(D2+13);
	__m512i D0_14 = _mm512_load_epi64(D0+14), D2_14 = _mm512_load_epi64(D2+14);
	__m512i D0_15 = _mm512_load_epi64(D0+15), D2_15 = _mm512_load_epi64(D2+15);
	__m512i D0_16 = _mm512_load_epi64(D0+16), D2_16 = _mm512_load_epi64(D2+16);
	__m512i D0_17 = _mm512_load_epi64(D0+17), D2_17 = _mm512_load_epi64(D2+17);
	__m512i D0_18 = _mm512_load_epi64(D0+18), D2_18 = _mm512_load_epi64(D2+18);
	__m512i D0_19 = _mm512_load_epi64(D0+19), D2_19 = _mm512_load_epi64(D2+19);
	__m512i D0_20 = _mm512_load_epi64(D0+20), D2_20 = _mm512_load_epi64(D2+20);
	__m512i D0_21 = _mm512_load_epi64(D0+21), D2_21 = _mm512_load_epi64(D2+21);
	__m512i D0_22 = _mm512_load_epi64(D0+22), D2_22 = _mm512_load_epi64(D2+22);
	__m512i D0_23 = _mm512_load_epi64(D0+23), D2_23 = _mm512_load_epi64(D2+23);
	__m512i D0_24 = _mm512_load_epi64(D0+24), D2_24 = _mm512_load_epi64(D2+24);
	__m512i D0_25 = _mm512_load_epi64(D0+25), D2_25 = _mm512_load_epi64(D2+25);
	__m512i D0_26 = _mm512_load_epi64(D0+26), D2_26 = _mm512_load_epi64(D2+26);
	__m512i D0_27 = _mm512_load_epi64(D0+27), D2_27 = _mm512_load_epi64(D2+27);
	__m512i D0_28 = _mm512_load_epi64(D0+28), D2_28 = _mm512_load_epi64(D2+28);
	__m512i D0_29 = _mm512_load_epi64(D0+29), D2_29 = _mm512_load_epi64(D2+29);
	__m512i D0_30 = _mm512_load_epi64(D0+30), D2_30 = _mm512_load_epi64(D2+30);
	__m512i D0_31 = _mm512_load_epi64(D0+31), D2_31 = _mm512_load_epi64(D2+31);
	__m512i D0_32 = _mm512_load_epi64(D0+32), D2_32 = _mm512_load_epi64(D2+32);
	__m512i D0_33 = _mm512_load_epi64(D0+33), D2_33 = _mm512_load_epi64(D2+33);
	__m512i D0_34 = _mm512_load_epi64(D0+34), D2_34 = _mm512_load_epi64(D2+34);
	__m512i D0_35 = _mm512_load_epi64(D0+35), D2_35 = _mm512_load_epi64(D2+35);
	__m512i D0_36 = _mm512_load_epi64(D0+36), D2_36 = _mm512_load_epi64(D2+36);
	__m512i D0_37 = _mm512_load_epi64(D0+37), D2_37 = _mm512_load_epi64(D2+37);
	__m512i D0_38 = _mm512_load_epi64(D0+38), D2_38 = _mm512_load_epi64(D2+38);
	__m512i D0_39 = _mm512_load_epi64(D0+39), D2_39 = _mm512_load_epi64(D2+39);
	
	
	__m512i D0_40 = _mm512_load_epi64(D0+40);
	__m512i D0_41 = _mm512_load_epi64(D0+41);
	__m512i D0_42 = _mm512_load_epi64(D0+42);
	__m512i D0_43 = _mm512_load_epi64(D0+43);
	__m512i D0_44 = _mm512_load_epi64(D0+44);
	__m512i D0_45 = _mm512_load_epi64(D0+45);
	__m512i D0_46 = _mm512_load_epi64(D0+46);
	__m512i D0_47 = _mm512_load_epi64(D0+47);
	__m512i D0_48 = _mm512_load_epi64(D0+48);
	__m512i D0_49 = _mm512_load_epi64(D0+49);
	__m512i D0_50 = _mm512_load_epi64(D0+50);
	__m512i D0_51 = _mm512_load_epi64(D0+51);
	__m512i D0_52 = _mm512_load_epi64(D0+52);
	__m512i D0_53 = _mm512_load_epi64(D0+53);
	__m512i D0_54 = _mm512_load_epi64(D0+54);
	__m512i D0_55 = _mm512_load_epi64(D0+55);
	__m512i D0_56 = _mm512_load_epi64(D0+56);
	__m512i D0_57 = _mm512_load_epi64(D0+57);
	__m512i D0_58 = _mm512_load_epi64(D0+58);
	__m512i D0_59 = _mm512_load_epi64(D0+59);
	__m512i D0_60 = _mm512_load_epi64(D0+60);
	__m512i D0_61 = _mm512_load_epi64(D0+61);
	__m512i D0_62 = _mm512_load_epi64(D0+62);
	__m512i D0_63 = _mm512_load_epi64(D0+63);
	__m512i D0_64 = _mm512_load_epi64(D0+64);
	__m512i D0_65 = _mm512_load_epi64(D0+65);
	__m512i D0_66 = _mm512_load_epi64(D0+66);
	__m512i D0_67 = _mm512_load_epi64(D0+67);
	__m512i D0_68 = _mm512_load_epi64(D0+68);
	__m512i D0_69 = _mm512_load_epi64(D0+69);
	__m512i D0_70 = _mm512_load_epi64(D0+70);
	__m512i D0_71 = _mm512_load_epi64(D0+71);
	__m512i D0_72 = _mm512_load_epi64(D0+72);
	__m512i D0_73 = _mm512_load_epi64(D0+73);
	__m512i D0_74 = _mm512_load_epi64(D0+74);
	__m512i D0_75 = _mm512_load_epi64(D0+75);
	__m512i D0_76 = _mm512_load_epi64(D0+76);
	__m512i D0_77 = _mm512_load_epi64(D0+77);
	__m512i D0_78 = _mm512_load_epi64(D0+78);
	__m512i D0_79 = _mm512_load_epi64(D0+79);
	
	/*
	//conversion D0 in radix 2^2077
	
	__m512i carry = D0_39>>49;	D0_40 = (D0_40<<1)+carry;
	D0_39 &= mask50;	carry = D0_40>>52;
	D0_41 = (D0_41<<1)+carry;	D0_40 &= mask52;
	carry = D0_41>>52;	D0_42 = (D0_42<<1)+carry;
	D0_41 &= mask52;	carry = D0_42>>52;
	D0_43 = (D0_43<<1)+carry;	D0_42 &= mask52;
	carry = D0_43>>52;	D0_44 = (D0_44<<1)+carry;
	D0_43 &= mask52;	carry = D0_44>>52;
	D0_45 = (D0_45<<1)+carry;	D0_44 &= mask52;
	carry = D0_45>>52;	D0_46 = (D0_46<<1)+carry;
	D0_45 &= mask52;	carry = D0_46>>52;
	D0_47 = (D0_47<<1)+carry;	D0_46 &= mask52;
	carry = D0_47>>52;	D0_48 = (D0_48<<1)+carry;
	D0_47 &= mask52;	carry = D0_48>>52;
	D0_49 = (D0_49<<1)+carry;	D0_48 &= mask52;
	carry = D0_49>>52;	D0_50 = (D0_50<<1)+carry;
	D0_49 &= mask52;	carry = D0_50>>52;
	D0_51 = (D0_51<<1)+carry;	D0_50 &= mask52;
	carry = D0_51>>52;	D0_52 = (D0_52<<1)+carry;
	D0_51 &= mask52;	carry = D0_52>>52;
	D0_53 = (D0_53<<1)+carry;	D0_52 &= mask52;
	carry = D0_53>>52;	D0_54 = (D0_54<<1)+carry;
	D0_53 &= mask52;	carry = D0_54>>52;
	D0_55 = (D0_55<<1)+carry;	D0_54 &= mask52;
	carry = D0_55>>52;	D0_56 = (D0_56<<1)+carry;
	D0_55 &= mask52;	carry = D0_56>>52;
	D0_57 = (D0_57<<1)+carry;
	D0_56 &= mask52;	carry = D0_57>>52;
	D0_58 = (D0_58<<1)+carry;	D0_57 &= mask52;
	carry = D0_58>>52;	D0_59 = (D0_59<<1)+carry;
	D0_58 &= mask52;	carry = D0_59>>52;
	D0_60 = (D0_60<<1)+carry;	D0_59 &= mask52;
	carry = D0_60>>52;	D0_61 = (D0_61<<1)+carry;
	D0_60 &= mask52;	carry = D0_61>>52;
	D0_62 = (D0_62<<1)+carry;	D0_61 &= mask52;
	carry = D0_62>>52;	D0_63 = (D0_63<<1)+carry;
	D0_62 &= mask52;	carry = D0_63>>52;
	D0_64 = (D0_64<<1)+carry;	D0_63 &= mask52;
	carry = D0_64>>52;	D0_65 = (D0_65<<1)+carry;
	D0_64 &= mask52;	carry = D0_65>>52;
	D0_66 = (D0_66<<1)+carry;	D0_65 &= mask52;
	carry = D0_66>>52;	D0_67 = (D0_67<<1)+carry;
	D0_66 &= mask52;	carry = D0_67>>52;
	D0_68 = (D0_68<<1)+carry;	D0_67 &= mask52;
	carry = D0_68>>52;	D0_69 = (D0_69<<1)+carry;
	D0_68 &= mask52;	carry = D0_69>>52;
	D0_70 = (D0_70<<1)+carry;	D0_69 &= mask52;
	carry = D0_70>>52;	D0_71 = (D0_71<<1)+carry;
	D0_70 &= mask52;	carry = D0_71>>52;
	D0_72 = (D0_72<<1)+carry;	D0_71 &= mask52;
	carry = D0_72>>52;	D0_73 = (D0_73<<1)+carry;
	D0_72 &= mask52;	carry = D0_73>>52;
	D0_74 = (D0_74<<1)+carry;	D0_73 &= mask52;
	carry = D0_74>>52;	D0_75 = (D0_75<<1)+carry;
	D0_74 &= mask52;	carry = D0_75>>52;
	D0_76 = (D0_76<<1)+carry;	D0_75 &= mask52;
	carry = D0_76>>52;	D0_77 = (D0_77<<1)+carry;
	D0_76 &= mask52;	carry = D0_77>>52;
	D0_78 = (D0_78<<1)+carry;	D0_77 &= mask52;
	carry = D0_78>>52;	D0_79 = (D0_79<<1)+carry;
	D0_78 &= mask52;
	

	//conversion D2 in radix 2^2077
	
	carry = D2_39>>49;	D2_40 = (D2_40<<1)+carry;
	D2_39 &= mask50;	carry = D2_40>>52;
	D2_41 = (D2_41<<1)+carry;	D2_40 &= mask52;
	carry = D2_41>>52;	D2_42 = (D2_42<<1)+carry;
	D2_41 &= mask52;	carry = D2_42>>52;
	D2_43 = (D2_43<<1)+carry;	D2_42 &= mask52;
	carry = D2_43>>52;	D2_44 = (D2_44<<1)+carry;
	D2_43 &= mask52;	carry = D2_44>>52;
	D2_45 = (D2_45<<1)+carry;	D2_44 &= mask52;
	carry = D2_45>>52;	D2_46 = (D2_46<<1)+carry;
	D2_45 &= mask52;	carry = D2_46>>52;
	D2_47 = (D2_47<<1)+carry;	D2_46 &= mask52;
	carry = D2_47>>52;	D2_48 = (D2_48<<1)+carry;
	D2_47 &= mask52;	carry = D2_48>>52;
	D2_49 = (D2_49<<1)+carry;	D2_48 &= mask52;
	carry = D2_49>>52;	D2_50 = (D2_50<<1)+carry;
	D2_49 &= mask52;	carry = D2_50>>52;
	D2_51 = (D2_51<<1)+carry;	D2_50 &= mask52;
	carry = D2_51>>52;	D2_52 = (D2_52<<1)+carry;
	D2_51 &= mask52;	carry = D2_52>>52;
	D2_53 = (D2_53<<1)+carry;	D2_52 &= mask52;
	carry = D2_53>>52;	D2_54 = (D2_54<<1)+carry;
	D2_53 &= mask52;	carry = D2_54>>52;
	D2_55 = (D2_55<<1)+carry;	D2_54 &= mask52;
	carry = D2_55>>52;	D2_56 = (D2_56<<1)+carry;
	D2_55 &= mask52;	carry = D2_56>>52;
	D2_57 = (D2_57<<1)+carry;
	D2_56 &= mask52;	carry = D2_57>>52;
	D2_58 = (D2_58<<1)+carry;	D2_57 &= mask52;
	carry = D2_58>>52;	D2_59 = (D2_59<<1)+carry;
	D2_58 &= mask52;	carry = D2_59>>52;
	D2_60 = (D2_60<<1)+carry;	D2_59 &= mask52;
	carry = D2_60>>52;	D2_61 = (D2_61<<1)+carry;
	D2_60 &= mask52;	carry = D2_61>>52;
	D2_62 = (D2_62<<1)+carry;	D2_61 &= mask52;
	carry = D2_62>>52;	D2_63 = (D2_63<<1)+carry;
	D2_62 &= mask52;	carry = D2_63>>52;
	D2_64 = (D2_64<<1)+carry;	D2_63 &= mask52;
	carry = D2_64>>52;	D2_65 = (D2_65<<1)+carry;
	D2_64 &= mask52;	carry = D2_65>>52;
	D2_66 = (D2_66<<1)+carry;	D2_65 &= mask52;
	carry = D2_66>>52;	D2_67 = (D2_67<<1)+carry;
	D2_66 &= mask52;	carry = D2_67>>52;
	D2_68 = (D2_68<<1)+carry;	D2_67 &= mask52;
	carry = D2_68>>52;	D2_69 = (D2_69<<1)+carry;
	D2_68 &= mask52;	carry = D2_69>>52;
	D2_70 = (D2_70<<1)+carry;	D2_69 &= mask52;
	carry = D2_70>>52;	D2_71 = (D2_71<<1)+carry;
	D2_70 &= mask52;	carry = D2_71>>52;
	D2_72 = (D2_72<<1)+carry;	D2_71 &= mask52;
	carry = D2_72>>52;	D2_73 = (D2_73<<1)+carry;
	D2_72 &= mask52;	carry = D2_73>>52;
	D2_74 = (D2_74<<1)+carry;	D2_73 &= mask52;
	carry = D2_74>>52;	D2_75 = (D2_75<<1)+carry;
	D2_74 &= mask52;	carry = D2_75>>52;
	D2_76 = (D2_76<<1)+carry;	D2_75 &= mask52;
	carry = D2_76>>52;	D2_77 = (D2_77<<1)+carry;
	D2_76 &= mask52;	carry = D2_77>>52;
	D2_78 = (D2_78<<1)+carry;	D2_77 &= mask52;
	carry = D2_78>>52;	D2_79 = (D2_79<<1)+carry;
	D2_78 &= mask52;//*/


	
	
	// Final Reconstruction
	

	// tmp = D0+D2, radix 2^2077/radix 2^1039
	/*__m512i tmp[160];
	
	add512_8_2078K(tmp, D0, D2);
	
	// Carry radix 2^2077
	tmp[40] = _mm512_srli_epi64(tmp[39],49);
	tmp[39] = _mm512_and_si512(tmp[39],mask50);
	
	addC512_8_2078K(tmp+40, D0+40, D2+40);//*/
	

	// D1 = D1 -tmp, radix 2^2079/radix 2^1039
	
	/*add512_8_2078K(D1, D1, D0+40);
	
	add512_8_2078K(D1+40, D1+40, D2);
	
	__m512i borrow = sub512_8_4154K(D1, D1, tmp);
	
	//last borrow
	
	__m512i borrow = _mm512_srli_epi64(tmp[79],49);
	tmp[79] = _mm512_and_si512(tmp[79],mask50);//*/
	
	
	
	
	__m512i D1_0 = _mm512_load_epi64(D1);
	__m512i D1_1 = _mm512_load_epi64(D1+1);
	__m512i D1_2 = _mm512_load_epi64(D1+2);
	__m512i D1_3 = _mm512_load_epi64(D1+3);
	__m512i D1_4 = _mm512_load_epi64(D1+4);
	__m512i D1_5 = _mm512_load_epi64(D1+5);
	__m512i D1_6 = _mm512_load_epi64(D1+6);
	__m512i D1_7 = _mm512_load_epi64(D1+7);
	__m512i D1_8 = _mm512_load_epi64(D1+8);
	__m512i D1_9 = _mm512_load_epi64(D1+9);
	__m512i D1_10 = _mm512_load_epi64(D1+10);
	__m512i D1_11 = _mm512_load_epi64(D1+11);
	__m512i D1_12 = _mm512_load_epi64(D1+12);
	__m512i D1_13 = _mm512_load_epi64(D1+13);
	__m512i D1_14 = _mm512_load_epi64(D1+14);
	__m512i D1_15 = _mm512_load_epi64(D1+15);
	__m512i D1_16 = _mm512_load_epi64(D1+16);
	__m512i D1_17 = _mm512_load_epi64(D1+17);
	__m512i D1_18 = _mm512_load_epi64(D1+18);
	__m512i D1_19 = _mm512_load_epi64(D1+19);
	__m512i D1_20 = _mm512_load_epi64(D1+20);
	__m512i D1_21 = _mm512_load_epi64(D1+21);
	__m512i D1_22 = _mm512_load_epi64(D1+22);
	__m512i D1_23 = _mm512_load_epi64(D1+23);
	__m512i D1_24 = _mm512_load_epi64(D1+24);
	__m512i D1_25 = _mm512_load_epi64(D1+25);
	__m512i D1_26 = _mm512_load_epi64(D1+26);
	__m512i D1_27 = _mm512_load_epi64(D1+27);
	__m512i D1_28 = _mm512_load_epi64(D1+28);
	__m512i D1_29 = _mm512_load_epi64(D1+29);
	__m512i D1_30 = _mm512_load_epi64(D1+30);
	__m512i D1_31 = _mm512_load_epi64(D1+31);
	__m512i D1_32 = _mm512_load_epi64(D1+32);
	__m512i D1_33 = _mm512_load_epi64(D1+33);
	__m512i D1_34 = _mm512_load_epi64(D1+34);
	__m512i D1_35 = _mm512_load_epi64(D1+35);
	__m512i D1_36 = _mm512_load_epi64(D1+36);
	__m512i D1_37 = _mm512_load_epi64(D1+37);
	__m512i D1_38 = _mm512_load_epi64(D1+38);
	__m512i D1_39 = _mm512_load_epi64(D1+39);


	/*
	//conversion D2 in radix 2^2077
	
	carry = D1_39>>49;	D1_40 = (D1_40<<1)+carry;
	D1_39 &= mask50;	carry = D1_40>>52;
	D1_41 = (D1_41<<1)+carry;	D1_40 &= mask52;
	carry = D1_41>>52;	D1_42 = (D1_42<<1)+carry;
	D1_41 &= mask52;	carry = D1_42>>52;
	D1_43 = (D1_43<<1)+carry;	D1_42 &= mask52;
	carry = D1_43>>52;	D1_44 = (D1_44<<1)+carry;
	D1_43 &= mask52;	carry = D1_44>>52;
	D1_45 = (D1_45<<1)+carry;	D1_44 &= mask52;
	carry = D1_45>>52;	D1_46 = (D1_46<<1)+carry;
	D1_45 &= mask52;	carry = D1_46>>52;
	D1_47 = (D1_47<<1)+carry;	D1_46 &= mask52;
	carry = D1_47>>52;	D1_48 = (D1_48<<1)+carry;
	D1_47 &= mask52;	carry = D1_48>>52;
	D1_49 = (D1_49<<1)+carry;	D1_48 &= mask52;
	carry = D1_49>>52;	D1_50 = (D1_50<<1)+carry;
	D1_49 &= mask52;	carry = D1_50>>52;
	D1_51 = (D1_51<<1)+carry;	D1_50 &= mask52;
	carry = D1_51>>52;	D1_52 = (D1_52<<1)+carry;
	D1_51 &= mask52;	carry = D1_52>>52;
	D1_53 = (D1_53<<1)+carry;	D1_52 &= mask52;
	carry = D1_53>>52;	D1_54 = (D1_54<<1)+carry;
	D1_53 &= mask52;	carry = D1_54>>52;
	D1_55 = (D1_55<<1)+carry;	D1_54 &= mask52;
	carry = D1_55>>52;	D1_56 = (D1_56<<1)+carry;
	D1_55 &= mask52;	carry = D1_56>>52;
	D1_57 = (D1_57<<1)+carry;
	D1_56 &= mask52;	carry = D1_57>>52;
	D1_58 = (D1_58<<1)+carry;	D1_57 &= mask52;
	carry = D1_58>>52;	D1_59 = (D1_59<<1)+carry;
	D1_58 &= mask52;	carry = D1_59>>52;
	D1_60 = (D1_60<<1)+carry;	D1_59 &= mask52;
	carry = D1_60>>52;	D1_61 = (D1_61<<1)+carry;
	D1_60 &= mask52;	carry = D1_61>>52;
	D1_62 = (D1_62<<1)+carry;	D1_61 &= mask52;
	carry = D1_62>>52;	D1_63 = (D1_63<<1)+carry;
	D1_62 &= mask52;	carry = D1_63>>52;
	D1_64 = (D1_64<<1)+carry;	D1_63 &= mask52;
	carry = D1_64>>52;	D1_65 = (D1_65<<1)+carry;
	D1_64 &= mask52;	carry = D1_65>>52;
	D1_66 = (D1_66<<1)+carry;	D1_65 &= mask52;
	carry = D1_66>>52;	D1_67 = (D1_67<<1)+carry;
	D1_66 &= mask52;	carry = D1_67>>52;
	D1_68 = (D1_68<<1)+carry;	D1_67 &= mask52;
	carry = D1_68>>52;	D1_69 = (D1_69<<1)+carry;
	D1_68 &= mask52;	carry = D1_69>>52;
	D1_70 = (D1_70<<1)+carry;	D1_69 &= mask52;
	carry = D1_70>>52;	D1_71 = (D1_71<<1)+carry;
	D1_70 &= mask52;	carry = D1_71>>52;
	D1_72 = (D1_72<<1)+carry;	D1_71 &= mask52;
	carry = D1_72>>52;	D1_73 = (D1_73<<1)+carry;
	D1_72 &= mask52;	carry = D1_73>>52;
	D1_74 = (D1_74<<1)+carry;	D1_73 &= mask52;
	carry = D1_74>>52;	D1_75 = (D1_75<<1)+carry;
	D1_74 &= mask52;	carry = D1_75>>52;
	D1_76 = (D1_76<<1)+carry;	D1_75 &= mask52;
	carry = D1_76>>52;	D1_77 = (D1_77<<1)+carry;
	D1_76 &= mask52;	carry = D1_77>>52;
	D1_78 = (D1_78<<1)+carry;	D1_77 &= mask52;
	carry = D1_78>>52;	D1_79 = (D1_79<<1)+carry;
	D1_78 &= mask52;//*/


	__m512i borrow, carry, carry_D1;
	borrow = _mm512_add_epi64(D0_0,D2_0);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_0 = _mm512_add_epi64(D1_0,D0_40);
	carry_D1 = _mm512_srli_epi64(D1_0,52);
	D1_0 = _mm512_and_si512(D1_0,mask52);
	D1_0 = _mm512_sub_epi64(D1_0,borrow);
	borrow  = _mm512_srli_epi64(D1_0,52)&un;
	D1_0 = _mm512_and_si512(D1_0,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_1);
	borrow = _mm512_add_epi64(borrow,D0_1);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_1 = _mm512_add_epi64(D1_1,carry_D1);
	D1_1 = _mm512_add_epi64(D1_1,D0_41);
	carry_D1 = _mm512_srli_epi64(D1_1,52);
	D1_1 = _mm512_and_si512(D1_1,mask52);
	D1_1 = _mm512_sub_epi64(D1_1,borrow);
	borrow  = _mm512_srli_epi64(D1_1,52)&un;
	D1_1 = _mm512_and_si512(D1_1,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_2);
	borrow = _mm512_add_epi64(borrow,D0_2);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_2 = _mm512_add_epi64(D1_2,carry_D1);
	D1_2 = _mm512_add_epi64(D1_2,D0_42);
	carry_D1 = _mm512_srli_epi64(D1_2,52);
	D1_2 = _mm512_and_si512(D1_2,mask52);
	D1_2 = _mm512_sub_epi64(D1_2,borrow);
	borrow  = _mm512_srli_epi64(D1_2,52)&un;
	D1_2 = _mm512_and_si512(D1_2,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_3);
	borrow = _mm512_add_epi64(borrow,D0_3);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_3 = _mm512_add_epi64(D1_3,carry_D1);
	D1_3 = _mm512_add_epi64(D1_3,D0_43);
	carry_D1 = _mm512_srli_epi64(D1_3,52);
	D1_3 = _mm512_and_si512(D1_3,mask52);
	D1_3 = _mm512_sub_epi64(D1_3,borrow);
	borrow  = _mm512_srli_epi64(D1_3,52)&un;
	D1_3 = _mm512_and_si512(D1_3,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_4);
	borrow = _mm512_add_epi64(borrow,D0_4);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_4 = _mm512_add_epi64(D1_4,carry_D1);
	D1_4 = _mm512_add_epi64(D1_4,D0_44);
	carry_D1 = _mm512_srli_epi64(D1_4,52);
	D1_4 = _mm512_and_si512(D1_4,mask52);
	D1_4 = _mm512_sub_epi64(D1_4,borrow);
	borrow  = _mm512_srli_epi64(D1_4,52)&un;
	D1_4 = _mm512_and_si512(D1_4,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_5);
	borrow = _mm512_add_epi64(borrow,D0_5);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_5 = _mm512_add_epi64(D1_5,carry_D1);
	D1_5 = _mm512_add_epi64(D1_5,D0_45);
	carry_D1 = _mm512_srli_epi64(D1_5,52);
	D1_5 = _mm512_and_si512(D1_5,mask52);
	D1_5 = _mm512_sub_epi64(D1_5,borrow);
	borrow  = _mm512_srli_epi64(D1_5,52)&un;
	D1_5 = _mm512_and_si512(D1_5,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_6);
	borrow = _mm512_add_epi64(borrow,D0_6);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_6 = _mm512_add_epi64(D1_6,carry_D1);
	D1_6 = _mm512_add_epi64(D1_6,D0_46);
	carry_D1 = _mm512_srli_epi64(D1_6,52);
	D1_6 = _mm512_and_si512(D1_6,mask52);
	D1_6 = _mm512_sub_epi64(D1_6,borrow);
	borrow  = _mm512_srli_epi64(D1_6,52)&un;
	D1_6 = _mm512_and_si512(D1_6,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_7);
	borrow = _mm512_add_epi64(borrow,D0_7);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_7 = _mm512_add_epi64(D1_7,carry_D1);
	D1_7 = _mm512_add_epi64(D1_7,D0_47);
	carry_D1 = _mm512_srli_epi64(D1_7,52);
	D1_7 = _mm512_and_si512(D1_7,mask52);
	D1_7 = _mm512_sub_epi64(D1_7,borrow);
	borrow  = _mm512_srli_epi64(D1_7,52)&un;
	D1_7 = _mm512_and_si512(D1_7,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_8);
	borrow = _mm512_add_epi64(borrow,D0_8);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_8 = _mm512_add_epi64(D1_8,carry_D1);
	D1_8 = _mm512_add_epi64(D1_8,D0_48);
	carry_D1 = _mm512_srli_epi64(D1_8,52);
	D1_8 = _mm512_and_si512(D1_8,mask52);
	D1_8 = _mm512_sub_epi64(D1_8,borrow);
	borrow  = _mm512_srli_epi64(D1_8,52)&un;
	D1_8 = _mm512_and_si512(D1_8,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_9);
	borrow = _mm512_add_epi64(borrow,D0_9);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_9 = _mm512_add_epi64(D1_9,carry_D1);
	D1_9 = _mm512_add_epi64(D1_9,D0_49);
	carry_D1 = _mm512_srli_epi64(D1_9,52);
	D1_9 = _mm512_and_si512(D1_9,mask52);
	D1_9 = _mm512_sub_epi64(D1_9,borrow);
	borrow  = _mm512_srli_epi64(D1_9,52)&un;
	D1_9 = _mm512_and_si512(D1_9,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_10);
	borrow = _mm512_add_epi64(borrow,D0_10);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_10 = _mm512_add_epi64(D1_10,carry_D1);
	D1_10 = _mm512_add_epi64(D1_10,D0_50);
	carry_D1 = _mm512_srli_epi64(D1_10,52);
	D1_10 = _mm512_and_si512(D1_10,mask52);
	D1_10 = _mm512_sub_epi64(D1_10,borrow);
	borrow  = _mm512_srli_epi64(D1_10,52)&un;
	D1_10 = _mm512_and_si512(D1_10,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_11);
	borrow = _mm512_add_epi64(borrow,D0_11);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_11 = _mm512_add_epi64(D1_11,carry_D1);
	D1_11 = _mm512_add_epi64(D1_11,D0_51);
	carry_D1 = _mm512_srli_epi64(D1_11,52);
	D1_11 = _mm512_and_si512(D1_11,mask52);
	D1_11 = _mm512_sub_epi64(D1_11,borrow);
	borrow  = _mm512_srli_epi64(D1_11,52)&un;
	D1_11 = _mm512_and_si512(D1_11,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_12);
	borrow = _mm512_add_epi64(borrow,D0_12);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_12 = _mm512_add_epi64(D1_12,carry_D1);
	D1_12 = _mm512_add_epi64(D1_12,D0_52);
	carry_D1 = _mm512_srli_epi64(D1_12,52);
	D1_12 = _mm512_and_si512(D1_12,mask52);
	D1_12 = _mm512_sub_epi64(D1_12,borrow);
	borrow  = _mm512_srli_epi64(D1_12,52)&un;
	D1_12 = _mm512_and_si512(D1_12,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_13);
	borrow = _mm512_add_epi64(borrow,D0_13);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_13 = _mm512_add_epi64(D1_13,carry_D1);
	D1_13 = _mm512_add_epi64(D1_13,D0_53);
	carry_D1 = _mm512_srli_epi64(D1_13,52);
	D1_13 = _mm512_and_si512(D1_13,mask52);
	D1_13 = _mm512_sub_epi64(D1_13,borrow);
	borrow  = _mm512_srli_epi64(D1_13,52)&un;
	D1_13 = _mm512_and_si512(D1_13,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_14);
	borrow = _mm512_add_epi64(borrow,D0_14);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_14 = _mm512_add_epi64(D1_14,carry_D1);
	D1_14 = _mm512_add_epi64(D1_14,D0_54);
	carry_D1 = _mm512_srli_epi64(D1_14,52);
	D1_14 = _mm512_and_si512(D1_14,mask52);
	D1_14 = _mm512_sub_epi64(D1_14,borrow);
	borrow  = _mm512_srli_epi64(D1_14,52)&un;
	D1_14 = _mm512_and_si512(D1_14,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_15);
	borrow = _mm512_add_epi64(borrow,D0_15);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_15 = _mm512_add_epi64(D1_15,carry_D1);
	D1_15 = _mm512_add_epi64(D1_15,D0_55);
	carry_D1 = _mm512_srli_epi64(D1_15,52);
	D1_15 = _mm512_and_si512(D1_15,mask52);
	D1_15 = _mm512_sub_epi64(D1_15,borrow);
	borrow  = _mm512_srli_epi64(D1_15,52)&un;
	D1_15 = _mm512_and_si512(D1_15,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_16);
	borrow = _mm512_add_epi64(borrow,D0_16);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_16 = _mm512_add_epi64(D1_16,carry_D1);
	D1_16 = _mm512_add_epi64(D1_16,D0_56);
	carry_D1 = _mm512_srli_epi64(D1_16,52);
	D1_16 = _mm512_and_si512(D1_16,mask52);
	D1_16 = _mm512_sub_epi64(D1_16,borrow);
	borrow  = _mm512_srli_epi64(D1_16,52)&un;
	D1_16 = _mm512_and_si512(D1_16,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_17);
	borrow = _mm512_add_epi64(borrow,D0_17);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_17 = _mm512_add_epi64(D1_17,carry_D1);
	D1_17 = _mm512_add_epi64(D1_17,D0_57);
	carry_D1 = _mm512_srli_epi64(D1_17,52);
	D1_17 = _mm512_and_si512(D1_17,mask52);
	D1_17 = _mm512_sub_epi64(D1_17,borrow);
	borrow  = _mm512_srli_epi64(D1_17,52)&un;
	D1_17 = _mm512_and_si512(D1_17,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_18);
	borrow = _mm512_add_epi64(borrow,D0_18);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_18 = _mm512_add_epi64(D1_18,carry_D1);
	D1_18 = _mm512_add_epi64(D1_18,D0_58);
	carry_D1 = _mm512_srli_epi64(D1_18,52);
	D1_18 = _mm512_and_si512(D1_18,mask52);
	D1_18 = _mm512_sub_epi64(D1_18,borrow);
	borrow  = _mm512_srli_epi64(D1_18,52)&un;
	D1_18 = _mm512_and_si512(D1_18,mask52);

	borrow = _mm512_add_epi64(carry,borrow); // radix 2^1039
	borrow = _mm512_add_epi64(borrow,D2_19);
	borrow = _mm512_add_epi64(borrow,D0_19);
	carry = _mm512_srli_epi64(borrow,51);
	borrow = _mm512_and_si512(borrow,mask51);
	D1_19 = _mm512_add_epi64(D1_19,carry_D1);
	D1_19 = _mm512_add_epi64(D1_19,D0_59);
	carry_D1 = _mm512_srli_epi64(D1_19,51);
	D1_19 = _mm512_and_si512(D1_19,mask51);
	D1_19 = _mm512_sub_epi64(D1_19,borrow);
	borrow  = _mm512_srli_epi64(D1_19,51)&un;
	D1_19 = _mm512_and_si512(D1_19,mask51);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_20);
	borrow = _mm512_add_epi64(borrow,D0_20);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_20 = _mm512_add_epi64(D1_20,carry_D1);
	D1_20 = _mm512_add_epi64(D1_20,D0_60);
	carry_D1 = _mm512_srli_epi64(D1_20,52);
	D1_20 = _mm512_and_si512(D1_20,mask52);
	D1_20 = _mm512_sub_epi64(D1_20,borrow);
	borrow  = _mm512_srli_epi64(D1_20,52)&un;
	D1_20 = _mm512_and_si512(D1_20,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_21);
	borrow = _mm512_add_epi64(borrow,D0_21);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_21 = _mm512_add_epi64(D1_21,carry_D1);
	D1_21 = _mm512_add_epi64(D1_21,D0_61);
	carry_D1 = _mm512_srli_epi64(D1_21,52);
	D1_21 = _mm512_and_si512(D1_21,mask52);
	D1_21 = _mm512_sub_epi64(D1_21,borrow);
	borrow  = _mm512_srli_epi64(D1_21,52)&un;
	D1_21 = _mm512_and_si512(D1_21,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_22);
	borrow = _mm512_add_epi64(borrow,D0_22);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_22 = _mm512_add_epi64(D1_22,carry_D1);
	D1_22 = _mm512_add_epi64(D1_22,D0_62);
	carry_D1 = _mm512_srli_epi64(D1_22,52);
	D1_22 = _mm512_and_si512(D1_22,mask52);
	D1_22 = _mm512_sub_epi64(D1_22,borrow);
	borrow  = _mm512_srli_epi64(D1_22,52)&un;
	D1_22 = _mm512_and_si512(D1_22,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_23);
	borrow = _mm512_add_epi64(borrow,D0_23);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_23 = _mm512_add_epi64(D1_23,carry_D1);
	D1_23 = _mm512_add_epi64(D1_23,D0_63);
	carry_D1 = _mm512_srli_epi64(D1_23,52);
	D1_23 = _mm512_and_si512(D1_23,mask52);
	D1_23 = _mm512_sub_epi64(D1_23,borrow);
	borrow  = _mm512_srli_epi64(D1_23,52)&un;
	D1_23 = _mm512_and_si512(D1_23,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_24);
	borrow = _mm512_add_epi64(borrow,D0_24);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_24 = _mm512_add_epi64(D1_24,carry_D1);
	D1_24 = _mm512_add_epi64(D1_24,D0_64);
	carry_D1 = _mm512_srli_epi64(D1_24,52);
	D1_24 = _mm512_and_si512(D1_24,mask52);
	D1_24 = _mm512_sub_epi64(D1_24,borrow);
	borrow  = _mm512_srli_epi64(D1_24,52)&un;
	D1_24 = _mm512_and_si512(D1_24,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_25);
	borrow = _mm512_add_epi64(borrow,D0_25);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_25 = _mm512_add_epi64(D1_25,carry_D1);
	D1_25 = _mm512_add_epi64(D1_25,D0_65);
	carry_D1 = _mm512_srli_epi64(D1_25,52);
	D1_25 = _mm512_and_si512(D1_25,mask52);
	D1_25 = _mm512_sub_epi64(D1_25,borrow);
	borrow  = _mm512_srli_epi64(D1_25,52)&un;
	D1_25 = _mm512_and_si512(D1_25,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_26);
	borrow = _mm512_add_epi64(borrow,D0_26);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_26 = _mm512_add_epi64(D1_26,carry_D1);
	D1_26 = _mm512_add_epi64(D1_26,D0_66);
	carry_D1 = _mm512_srli_epi64(D1_26,52);
	D1_26 = _mm512_and_si512(D1_26,mask52);
	D1_26 = _mm512_sub_epi64(D1_26,borrow);
	borrow  = _mm512_srli_epi64(D1_26,52)&un;
	D1_26 = _mm512_and_si512(D1_26,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_27);
	borrow = _mm512_add_epi64(borrow,D0_27);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_27 = _mm512_add_epi64(D1_27,carry_D1);
	D1_27 = _mm512_add_epi64(D1_27,D0_67);
	carry_D1 = _mm512_srli_epi64(D1_27,52);
	D1_27 = _mm512_and_si512(D1_27,mask52);
	D1_27 = _mm512_sub_epi64(D1_27,borrow);
	borrow  = _mm512_srli_epi64(D1_27,52)&un;
	D1_27 = _mm512_and_si512(D1_27,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_28);
	borrow = _mm512_add_epi64(borrow,D0_28);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_28 = _mm512_add_epi64(D1_28,carry_D1);
	D1_28 = _mm512_add_epi64(D1_28,D0_68);
	carry_D1 = _mm512_srli_epi64(D1_28,52);
	D1_28 = _mm512_and_si512(D1_28,mask52);
	D1_28 = _mm512_sub_epi64(D1_28,borrow);
	borrow  = _mm512_srli_epi64(D1_28,52)&un;
	D1_28 = _mm512_and_si512(D1_28,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_29);
	borrow = _mm512_add_epi64(borrow,D0_29);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_29 = _mm512_add_epi64(D1_29,carry_D1);
	D1_29 = _mm512_add_epi64(D1_29,D0_69);
	carry_D1 = _mm512_srli_epi64(D1_29,52);
	D1_29 = _mm512_and_si512(D1_29,mask52);
	D1_29 = _mm512_sub_epi64(D1_29,borrow);
	borrow  = _mm512_srli_epi64(D1_29,52)&un;
	D1_29 = _mm512_and_si512(D1_29,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_30);
	borrow = _mm512_add_epi64(borrow,D0_30);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_30 = _mm512_add_epi64(D1_30,carry_D1);
	D1_30 = _mm512_add_epi64(D1_30,D0_70);
	carry_D1 = _mm512_srli_epi64(D1_30,52);
	D1_30 = _mm512_and_si512(D1_30,mask52);
	D1_30 = _mm512_sub_epi64(D1_30,borrow);
	borrow  = _mm512_srli_epi64(D1_30,52)&un;
	D1_30 = _mm512_and_si512(D1_30,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_31);
	borrow = _mm512_add_epi64(borrow,D0_31);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_31 = _mm512_add_epi64(D1_31,carry_D1);
	D1_31 = _mm512_add_epi64(D1_31,D0_71);
	carry_D1 = _mm512_srli_epi64(D1_31,52);
	D1_31 = _mm512_and_si512(D1_31,mask52);
	D1_31 = _mm512_sub_epi64(D1_31,borrow);
	borrow  = _mm512_srli_epi64(D1_31,52)&un;
	D1_31 = _mm512_and_si512(D1_31,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_32);
	borrow = _mm512_add_epi64(borrow,D0_32);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_32 = _mm512_add_epi64(D1_32,carry_D1);
	D1_32 = _mm512_add_epi64(D1_32,D0_72);
	carry_D1 = _mm512_srli_epi64(D1_32,52);
	D1_32 = _mm512_and_si512(D1_32,mask52);
	D1_32 = _mm512_sub_epi64(D1_32,borrow);
	borrow  = _mm512_srli_epi64(D1_32,52)&un;
	D1_32 = _mm512_and_si512(D1_32,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_33);
	borrow = _mm512_add_epi64(borrow,D0_33);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_33 = _mm512_add_epi64(D1_33,carry_D1);
	D1_33 = _mm512_add_epi64(D1_33,D0_73);
	carry_D1 = _mm512_srli_epi64(D1_33,52);
	D1_33 = _mm512_and_si512(D1_33,mask52);
	D1_33 = _mm512_sub_epi64(D1_33,borrow);
	borrow  = _mm512_srli_epi64(D1_33,52)&un;
	D1_33 = _mm512_and_si512(D1_33,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_34);
	borrow = _mm512_add_epi64(borrow,D0_34);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_34 = _mm512_add_epi64(D1_34,carry_D1);
	D1_34 = _mm512_add_epi64(D1_34,D0_74);
	carry_D1 = _mm512_srli_epi64(D1_34,52);
	D1_34 = _mm512_and_si512(D1_34,mask52);
	D1_34 = _mm512_sub_epi64(D1_34,borrow);
	borrow  = _mm512_srli_epi64(D1_34,52)&un;
	D1_34 = _mm512_and_si512(D1_34,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_35);
	borrow = _mm512_add_epi64(borrow,D0_35);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_35 = _mm512_add_epi64(D1_35,carry_D1);
	D1_35 = _mm512_add_epi64(D1_35,D0_75);
	carry_D1 = _mm512_srli_epi64(D1_35,52);
	D1_35 = _mm512_and_si512(D1_35,mask52);
	D1_35 = _mm512_sub_epi64(D1_35,borrow);
	borrow  = _mm512_srli_epi64(D1_35,52)&un;
	D1_35 = _mm512_and_si512(D1_35,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_36);
	borrow = _mm512_add_epi64(borrow,D0_36);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_36 = _mm512_add_epi64(D1_36,carry_D1);
	D1_36 = _mm512_add_epi64(D1_36,D0_76);
	carry_D1 = _mm512_srli_epi64(D1_36,52);
	D1_36 = _mm512_and_si512(D1_36,mask52);
	D1_36 = _mm512_sub_epi64(D1_36,borrow);
	borrow  = _mm512_srli_epi64(D1_36,52)&un;
	D1_36 = _mm512_and_si512(D1_36,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_37);
	borrow = _mm512_add_epi64(borrow,D0_37);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_37 = _mm512_add_epi64(D1_37,carry_D1);
	D1_37 = _mm512_add_epi64(D1_37,D0_77);
	carry_D1 = _mm512_srli_epi64(D1_37,52);
	D1_37 = _mm512_and_si512(D1_37,mask52);
	D1_37 = _mm512_sub_epi64(D1_37,borrow);
	borrow  = _mm512_srli_epi64(D1_37,52)&un;
	D1_37 = _mm512_and_si512(D1_37,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_38);
	borrow = _mm512_add_epi64(borrow,D0_38);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_38 = _mm512_add_epi64(D1_38,carry_D1);
	D1_38 = _mm512_add_epi64(D1_38,D0_78);
	carry_D1 = _mm512_srli_epi64(D1_38,52);
	D1_38 = _mm512_and_si512(D1_38,mask52);
	D1_38 = _mm512_sub_epi64(D1_38,borrow);
	borrow  = _mm512_srli_epi64(D1_38,52)&un;
	D1_38 = _mm512_and_si512(D1_38,mask52);

	borrow = _mm512_add_epi64(carry,borrow); // radix 2^2077
	borrow = _mm512_add_epi64(borrow,D2_39);
	borrow = _mm512_add_epi64(borrow,D0_39);
	carry = _mm512_srli_epi64(borrow,50);
	borrow = _mm512_and_si512(borrow,mask50);
	D1_39 = _mm512_add_epi64(D1_39,carry_D1);
	D1_39 = _mm512_add_epi64(D1_39,D0_79);
	carry_D1 = _mm512_srli_epi64(D1_39,50);
	D1_39 = _mm512_and_si512(D1_39,mask50);
	D1_39 = _mm512_sub_epi64(D1_39,borrow);
	borrow  = _mm512_srli_epi64(D1_39,50)&un;
	D1_39 = _mm512_and_si512(D1_39,mask50);

	/*borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_40);
	borrow = _mm512_add_epi64(borrow,D0_40);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_40 = _mm512_add_epi64(D1_40,carry_D1);
	D1_40 = _mm512_add_epi64(D1_40,D2_0);
	carry_D1 = _mm512_srli_epi64(D1_40,52);
	D1_40 = _mm512_and_si512(D1_40,mask52);
	D1_40 = _mm512_sub_epi64(D1_40,borrow);
	borrow  = _mm512_srli_epi64(D1_40,52)&un;
	D1_40 = _mm512_and_si512(D1_40,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_41);
	borrow = _mm512_add_epi64(borrow,D0_41);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_41 = _mm512_add_epi64(D1_41,carry_D1);
	D1_41 = _mm512_add_epi64(D1_41,D2_1);
	carry_D1 = _mm512_srli_epi64(D1_41,52);
	D1_41 = _mm512_and_si512(D1_41,mask52);
	D1_41 = _mm512_sub_epi64(D1_41,borrow);
	borrow  = _mm512_srli_epi64(D1_41,52)&un;
	D1_41 = _mm512_and_si512(D1_41,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_42);
	borrow = _mm512_add_epi64(borrow,D0_42);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_42 = _mm512_add_epi64(D1_42,carry_D1);
	D1_42 = _mm512_add_epi64(D1_42,D2_2);
	carry_D1 = _mm512_srli_epi64(D1_42,52);
	D1_42 = _mm512_and_si512(D1_42,mask52);
	D1_42 = _mm512_sub_epi64(D1_42,borrow);
	borrow  = _mm512_srli_epi64(D1_42,52)&un;
	D1_42 = _mm512_and_si512(D1_42,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_43);
	borrow = _mm512_add_epi64(borrow,D0_43);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_43 = _mm512_add_epi64(D1_43,carry_D1);
	D1_43 = _mm512_add_epi64(D1_43,D2_3);
	carry_D1 = _mm512_srli_epi64(D1_43,52);
	D1_43 = _mm512_and_si512(D1_43,mask52);
	D1_43 = _mm512_sub_epi64(D1_43,borrow);
	borrow  = _mm512_srli_epi64(D1_43,52)&un;
	D1_43 = _mm512_and_si512(D1_43,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_44);
	borrow = _mm512_add_epi64(borrow,D0_44);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_44 = _mm512_add_epi64(D1_44,carry_D1);
	D1_44 = _mm512_add_epi64(D1_44,D2_4);
	carry_D1 = _mm512_srli_epi64(D1_44,52);
	D1_44 = _mm512_and_si512(D1_44,mask52);
	D1_44 = _mm512_sub_epi64(D1_44,borrow);
	borrow  = _mm512_srli_epi64(D1_44,52)&un;
	D1_44 = _mm512_and_si512(D1_44,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_45);
	borrow = _mm512_add_epi64(borrow,D0_45);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_45 = _mm512_add_epi64(D1_45,carry_D1);
	D1_45 = _mm512_add_epi64(D1_45,D2_5);
	carry_D1 = _mm512_srli_epi64(D1_45,52);
	D1_45 = _mm512_and_si512(D1_45,mask52);
	D1_45 = _mm512_sub_epi64(D1_45,borrow);
	borrow  = _mm512_srli_epi64(D1_45,52)&un;
	D1_45 = _mm512_and_si512(D1_45,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_46);
	borrow = _mm512_add_epi64(borrow,D0_46);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_46 = _mm512_add_epi64(D1_46,carry_D1);
	D1_46 = _mm512_add_epi64(D1_46,D2_6);
	carry_D1 = _mm512_srli_epi64(D1_46,52);
	D1_46 = _mm512_and_si512(D1_46,mask52);
	D1_46 = _mm512_sub_epi64(D1_46,borrow);
	borrow  = _mm512_srli_epi64(D1_46,52)&un;
	D1_46 = _mm512_and_si512(D1_46,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_47);
	borrow = _mm512_add_epi64(borrow,D0_47);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_47 = _mm512_add_epi64(D1_47,carry_D1);
	D1_47 = _mm512_add_epi64(D1_47,D2_7);
	carry_D1 = _mm512_srli_epi64(D1_47,52);
	D1_47 = _mm512_and_si512(D1_47,mask52);
	D1_47 = _mm512_sub_epi64(D1_47,borrow);
	borrow  = _mm512_srli_epi64(D1_47,52)&un;
	D1_47 = _mm512_and_si512(D1_47,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_48);
	borrow = _mm512_add_epi64(borrow,D0_48);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_48 = _mm512_add_epi64(D1_48,carry_D1);
	D1_48 = _mm512_add_epi64(D1_48,D2_8);
	carry_D1 = _mm512_srli_epi64(D1_48,52);
	D1_48 = _mm512_and_si512(D1_48,mask52);
	D1_48 = _mm512_sub_epi64(D1_48,borrow);
	borrow  = _mm512_srli_epi64(D1_48,52)&un;
	D1_48 = _mm512_and_si512(D1_48,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_49);
	borrow = _mm512_add_epi64(borrow,D0_49);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_49 = _mm512_add_epi64(D1_49,carry_D1);
	D1_49 = _mm512_add_epi64(D1_49,D2_9);
	carry_D1 = _mm512_srli_epi64(D1_49,52);
	D1_49 = _mm512_and_si512(D1_49,mask52);
	D1_49 = _mm512_sub_epi64(D1_49,borrow);
	borrow  = _mm512_srli_epi64(D1_49,52)&un;
	D1_49 = _mm512_and_si512(D1_49,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_50);
	borrow = _mm512_add_epi64(borrow,D0_50);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_50 = _mm512_add_epi64(D1_50,carry_D1);
	D1_50 = _mm512_add_epi64(D1_50,D2_10);
	carry_D1 = _mm512_srli_epi64(D1_50,52);
	D1_50 = _mm512_and_si512(D1_50,mask52);
	D1_50 = _mm512_sub_epi64(D1_50,borrow);
	borrow  = _mm512_srli_epi64(D1_50,52)&un;
	D1_50 = _mm512_and_si512(D1_50,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_51);
	borrow = _mm512_add_epi64(borrow,D0_51);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_51 = _mm512_add_epi64(D1_51,carry_D1);
	D1_51 = _mm512_add_epi64(D1_51,D2_11);
	carry_D1 = _mm512_srli_epi64(D1_51,52);
	D1_51 = _mm512_and_si512(D1_51,mask52);
	D1_51 = _mm512_sub_epi64(D1_51,borrow);
	borrow  = _mm512_srli_epi64(D1_51,52)&un;
	D1_51 = _mm512_and_si512(D1_51,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_52);
	borrow = _mm512_add_epi64(borrow,D0_52);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_52 = _mm512_add_epi64(D1_52,carry_D1);
	D1_52 = _mm512_add_epi64(D1_52,D2_12);
	carry_D1 = _mm512_srli_epi64(D1_52,52);
	D1_52 = _mm512_and_si512(D1_52,mask52);
	D1_52 = _mm512_sub_epi64(D1_52,borrow);
	borrow  = _mm512_srli_epi64(D1_52,52)&un;
	D1_52 = _mm512_and_si512(D1_52,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_53);
	borrow = _mm512_add_epi64(borrow,D0_53);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_53 = _mm512_add_epi64(D1_53,carry_D1);
	D1_53 = _mm512_add_epi64(D1_53,D2_13);
	carry_D1 = _mm512_srli_epi64(D1_53,52);
	D1_53 = _mm512_and_si512(D1_53,mask52);
	D1_53 = _mm512_sub_epi64(D1_53,borrow);
	borrow  = _mm512_srli_epi64(D1_53,52)&un;
	D1_53 = _mm512_and_si512(D1_53,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_54);
	borrow = _mm512_add_epi64(borrow,D0_54);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_54 = _mm512_add_epi64(D1_54,carry_D1);
	D1_54 = _mm512_add_epi64(D1_54,D2_14);
	carry_D1 = _mm512_srli_epi64(D1_54,52);
	D1_54 = _mm512_and_si512(D1_54,mask52);
	D1_54 = _mm512_sub_epi64(D1_54,borrow);
	borrow  = _mm512_srli_epi64(D1_54,52)&un;
	D1_54 = _mm512_and_si512(D1_54,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_55);
	borrow = _mm512_add_epi64(borrow,D0_55);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_55 = _mm512_add_epi64(D1_55,carry_D1);
	D1_55 = _mm512_add_epi64(D1_55,D2_15);
	carry_D1 = _mm512_srli_epi64(D1_55,52);
	D1_55 = _mm512_and_si512(D1_55,mask52);
	D1_55 = _mm512_sub_epi64(D1_55,borrow);
	borrow  = _mm512_srli_epi64(D1_55,52)&un;
	D1_55 = _mm512_and_si512(D1_55,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_56);
	borrow = _mm512_add_epi64(borrow,D0_56);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_56 = _mm512_add_epi64(D1_56,carry_D1);
	D1_56 = _mm512_add_epi64(D1_56,D2_16);
	carry_D1 = _mm512_srli_epi64(D1_56,52);
	D1_56 = _mm512_and_si512(D1_56,mask52);
	D1_56 = _mm512_sub_epi64(D1_56,borrow);
	borrow  = _mm512_srli_epi64(D1_56,52)&un;
	D1_56 = _mm512_and_si512(D1_56,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_57);
	borrow = _mm512_add_epi64(borrow,D0_57);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_57 = _mm512_add_epi64(D1_57,carry_D1);
	D1_57 = _mm512_add_epi64(D1_57,D2_17);
	carry_D1 = _mm512_srli_epi64(D1_57,52);
	D1_57 = _mm512_and_si512(D1_57,mask52);
	D1_57 = _mm512_sub_epi64(D1_57,borrow);
	borrow  = _mm512_srli_epi64(D1_57,52)&un;
	D1_57 = _mm512_and_si512(D1_57,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_58);
	borrow = _mm512_add_epi64(borrow,D0_58);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_58 = _mm512_add_epi64(D1_58,carry_D1);
	D1_58 = _mm512_add_epi64(D1_58,D2_18);
	carry_D1 = _mm512_srli_epi64(D1_58,52);
	D1_58 = _mm512_and_si512(D1_58,mask52);
	D1_58 = _mm512_sub_epi64(D1_58,borrow);
	borrow  = _mm512_srli_epi64(D1_58,52)&un;
	D1_58 = _mm512_and_si512(D1_58,mask52);

	borrow = _mm512_add_epi64(carry,borrow); // radix 2^1039
	borrow = _mm512_add_epi64(borrow,D2_59);
	borrow = _mm512_add_epi64(borrow,D0_59);
	carry = _mm512_srli_epi64(borrow,51);
	borrow = _mm512_and_si512(borrow,mask51);
	D1_59 = _mm512_add_epi64(D1_59,carry_D1);
	D1_59 = _mm512_add_epi64(D1_59,D2_19);
	carry_D1 = _mm512_srli_epi64(D1_59,51);
	D1_59 = _mm512_and_si512(D1_59,mask51);
	D1_59 = _mm512_sub_epi64(D1_59,borrow);
	borrow  = _mm512_srli_epi64(D1_59,51)&un;
	D1_59 = _mm512_and_si512(D1_59,mask51);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_60);
	borrow = _mm512_add_epi64(borrow,D0_60);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_60 = _mm512_add_epi64(D1_60,carry_D1);
	D1_60 = _mm512_add_epi64(D1_60,D2_20);
	carry_D1 = _mm512_srli_epi64(D1_60,52);
	D1_60 = _mm512_and_si512(D1_60,mask52);
	D1_60 = _mm512_sub_epi64(D1_60,borrow);
	borrow  = _mm512_srli_epi64(D1_60,52)&un;
	D1_60 = _mm512_and_si512(D1_60,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_61);
	borrow = _mm512_add_epi64(borrow,D0_61);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_61 = _mm512_add_epi64(D1_61,carry_D1);
	D1_61 = _mm512_add_epi64(D1_61,D2_21);
	carry_D1 = _mm512_srli_epi64(D1_61,52);
	D1_61 = _mm512_and_si512(D1_61,mask52);
	D1_61 = _mm512_sub_epi64(D1_61,borrow);
	borrow  = _mm512_srli_epi64(D1_61,52)&un;
	D1_61 = _mm512_and_si512(D1_61,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_62);
	borrow = _mm512_add_epi64(borrow,D0_62);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_62 = _mm512_add_epi64(D1_62,carry_D1);
	D1_62 = _mm512_add_epi64(D1_62,D2_22);
	carry_D1 = _mm512_srli_epi64(D1_62,52);
	D1_62 = _mm512_and_si512(D1_62,mask52);
	D1_62 = _mm512_sub_epi64(D1_62,borrow);
	borrow  = _mm512_srli_epi64(D1_62,52)&un;
	D1_62 = _mm512_and_si512(D1_62,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_63);
	borrow = _mm512_add_epi64(borrow,D0_63);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_63 = _mm512_add_epi64(D1_63,carry_D1);
	D1_63 = _mm512_add_epi64(D1_63,D2_23);
	carry_D1 = _mm512_srli_epi64(D1_63,52);
	D1_63 = _mm512_and_si512(D1_63,mask52);
	D1_63 = _mm512_sub_epi64(D1_63,borrow);
	borrow  = _mm512_srli_epi64(D1_63,52)&un;
	D1_63 = _mm512_and_si512(D1_63,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_64);
	borrow = _mm512_add_epi64(borrow,D0_64);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_64 = _mm512_add_epi64(D1_64,carry_D1);
	D1_64 = _mm512_add_epi64(D1_64,D2_24);
	carry_D1 = _mm512_srli_epi64(D1_64,52);
	D1_64 = _mm512_and_si512(D1_64,mask52);
	D1_64 = _mm512_sub_epi64(D1_64,borrow);
	borrow  = _mm512_srli_epi64(D1_64,52)&un;
	D1_64 = _mm512_and_si512(D1_64,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_65);
	borrow = _mm512_add_epi64(borrow,D0_65);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_65 = _mm512_add_epi64(D1_65,carry_D1);
	D1_65 = _mm512_add_epi64(D1_65,D2_25);
	carry_D1 = _mm512_srli_epi64(D1_65,52);
	D1_65 = _mm512_and_si512(D1_65,mask52);
	D1_65 = _mm512_sub_epi64(D1_65,borrow);
	borrow  = _mm512_srli_epi64(D1_65,52)&un;
	D1_65 = _mm512_and_si512(D1_65,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_66);
	borrow = _mm512_add_epi64(borrow,D0_66);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_66 = _mm512_add_epi64(D1_66,carry_D1);
	D1_66 = _mm512_add_epi64(D1_66,D2_26);
	carry_D1 = _mm512_srli_epi64(D1_66,52);
	D1_66 = _mm512_and_si512(D1_66,mask52);
	D1_66 = _mm512_sub_epi64(D1_66,borrow);
	borrow  = _mm512_srli_epi64(D1_66,52)&un;
	D1_66 = _mm512_and_si512(D1_66,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_67);
	borrow = _mm512_add_epi64(borrow,D0_67);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_67 = _mm512_add_epi64(D1_67,carry_D1);
	D1_67 = _mm512_add_epi64(D1_67,D2_27);
	carry_D1 = _mm512_srli_epi64(D1_67,52);
	D1_67 = _mm512_and_si512(D1_67,mask52);
	D1_67 = _mm512_sub_epi64(D1_67,borrow);
	borrow  = _mm512_srli_epi64(D1_67,52)&un;
	D1_67 = _mm512_and_si512(D1_67,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_68);
	borrow = _mm512_add_epi64(borrow,D0_68);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_68 = _mm512_add_epi64(D1_68,carry_D1);
	D1_68 = _mm512_add_epi64(D1_68,D2_28);
	carry_D1 = _mm512_srli_epi64(D1_68,52);
	D1_68 = _mm512_and_si512(D1_68,mask52);
	D1_68 = _mm512_sub_epi64(D1_68,borrow);
	borrow  = _mm512_srli_epi64(D1_68,52)&un;
	D1_68 = _mm512_and_si512(D1_68,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_69);
	borrow = _mm512_add_epi64(borrow,D0_69);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_69 = _mm512_add_epi64(D1_69,carry_D1);
	D1_69 = _mm512_add_epi64(D1_69,D2_29);
	carry_D1 = _mm512_srli_epi64(D1_69,52);
	D1_69 = _mm512_and_si512(D1_69,mask52);
	D1_69 = _mm512_sub_epi64(D1_69,borrow);
	borrow  = _mm512_srli_epi64(D1_69,52)&un;
	D1_69 = _mm512_and_si512(D1_69,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_70);
	borrow = _mm512_add_epi64(borrow,D0_70);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_70 = _mm512_add_epi64(D1_70,carry_D1);
	D1_70 = _mm512_add_epi64(D1_70,D2_30);
	carry_D1 = _mm512_srli_epi64(D1_70,52);
	D1_70 = _mm512_and_si512(D1_70,mask52);
	D1_70 = _mm512_sub_epi64(D1_70,borrow);
	borrow  = _mm512_srli_epi64(D1_70,52)&un;
	D1_70 = _mm512_and_si512(D1_70,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_71);
	borrow = _mm512_add_epi64(borrow,D0_71);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_71 = _mm512_add_epi64(D1_71,carry_D1);
	D1_71 = _mm512_add_epi64(D1_71,D2_31);
	carry_D1 = _mm512_srli_epi64(D1_71,52);
	D1_71 = _mm512_and_si512(D1_71,mask52);
	D1_71 = _mm512_sub_epi64(D1_71,borrow);
	borrow  = _mm512_srli_epi64(D1_71,52)&un;
	D1_71 = _mm512_and_si512(D1_71,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_72);
	borrow = _mm512_add_epi64(borrow,D0_72);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_72 = _mm512_add_epi64(D1_72,carry_D1);
	D1_72 = _mm512_add_epi64(D1_72,D2_32);
	carry_D1 = _mm512_srli_epi64(D1_72,52);
	D1_72 = _mm512_and_si512(D1_72,mask52);
	D1_72 = _mm512_sub_epi64(D1_72,borrow);
	borrow  = _mm512_srli_epi64(D1_72,52)&un;
	D1_72 = _mm512_and_si512(D1_72,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_73);
	borrow = _mm512_add_epi64(borrow,D0_73);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_73 = _mm512_add_epi64(D1_73,carry_D1);
	D1_73 = _mm512_add_epi64(D1_73,D2_33);
	carry_D1 = _mm512_srli_epi64(D1_73,52);
	D1_73 = _mm512_and_si512(D1_73,mask52);
	D1_73 = _mm512_sub_epi64(D1_73,borrow);
	borrow  = _mm512_srli_epi64(D1_73,52)&un;
	D1_73 = _mm512_and_si512(D1_73,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_74);
	borrow = _mm512_add_epi64(borrow,D0_74);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_74 = _mm512_add_epi64(D1_74,carry_D1);
	D1_74 = _mm512_add_epi64(D1_74,D2_34);
	carry_D1 = _mm512_srli_epi64(D1_74,52);
	D1_74 = _mm512_and_si512(D1_74,mask52);
	D1_74 = _mm512_sub_epi64(D1_74,borrow);
	borrow  = _mm512_srli_epi64(D1_74,52)&un;
	D1_74 = _mm512_and_si512(D1_74,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_75);
	borrow = _mm512_add_epi64(borrow,D0_75);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_75 = _mm512_add_epi64(D1_75,carry_D1);
	D1_75 = _mm512_add_epi64(D1_75,D2_35);
	carry_D1 = _mm512_srli_epi64(D1_75,52);
	D1_75 = _mm512_and_si512(D1_75,mask52);
	D1_75 = _mm512_sub_epi64(D1_75,borrow);
	borrow  = _mm512_srli_epi64(D1_75,52)&un;
	D1_75 = _mm512_and_si512(D1_75,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_76);
	borrow = _mm512_add_epi64(borrow,D0_76);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_76 = _mm512_add_epi64(D1_76,carry_D1);
	D1_76 = _mm512_add_epi64(D1_76,D2_36);
	carry_D1 = _mm512_srli_epi64(D1_76,52);
	D1_76 = _mm512_and_si512(D1_76,mask52);
	D1_76 = _mm512_sub_epi64(D1_76,borrow);
	borrow  = _mm512_srli_epi64(D1_76,52)&un;
	D1_76 = _mm512_and_si512(D1_76,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_77);
	borrow = _mm512_add_epi64(borrow,D0_77);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_77 = _mm512_add_epi64(D1_77,carry_D1);
	D1_77 = _mm512_add_epi64(D1_77,D2_37);
	carry_D1 = _mm512_srli_epi64(D1_77,52);
	D1_77 = _mm512_and_si512(D1_77,mask52);
	D1_77 = _mm512_sub_epi64(D1_77,borrow);
	borrow  = _mm512_srli_epi64(D1_77,52)&un;
	D1_77 = _mm512_and_si512(D1_77,mask52);

	borrow = _mm512_add_epi64(carry,borrow);
	borrow = _mm512_add_epi64(borrow,D2_78);
	borrow = _mm512_add_epi64(borrow,D0_78);
	carry = _mm512_srli_epi64(borrow,52);
	borrow = _mm512_and_si512(borrow,mask52);
	D1_78 = _mm512_add_epi64(D1_78,carry_D1);
	D1_78 = _mm512_add_epi64(D1_78,D2_38);
	carry_D1 = _mm512_srli_epi64(D1_78,52);
	D1_78 = _mm512_and_si512(D1_78,mask52);
	D1_78 = _mm512_sub_epi64(D1_78,borrow);
	borrow  = _mm512_srli_epi64(D1_78,52)&un;
	D1_78 = _mm512_and_si512(D1_78,mask52);

	borrow = _mm512_add_epi64(carry,borrow); // radix 2^2077
	borrow = _mm512_add_epi64(borrow,D2_79);
	borrow = _mm512_add_epi64(borrow,D0_79);
	carry = _mm512_srli_epi64(borrow,50);
	borrow = _mm512_and_si512(borrow,mask50);
	D1_79 = _mm512_add_epi64(D1_79,carry_D1);
	D1_79 = _mm512_add_epi64(D1_79,D2_39);
	carry_D1 = _mm512_srli_epi64(D1_79,50);
	D1_79 = _mm512_and_si512(D1_79,mask50);
	D1_79 = _mm512_sub_epi64(D1_79,borrow);
	borrow  = _mm512_srli_epi64(D1_79,50)&un;
	D1_79 = _mm512_and_si512(D1_79,mask50);


	// Final borrows
	D2_40 = _mm512_add_epi64(D2_40,carry_D1);
	
	borrow = _mm512_add_epi64(carry,borrow);
	D2_40 = _mm512_sub_epi64(D2_40,borrow);
	//borrow  = _mm512_srli_epi64(D2_40,52)&un;
	D2_40 = _mm512_and_si512(D2_40,mask52);//*/
	
	
	

	/*borrow = _mm512_add_epi64(carry_tmp,borrow);
	D2_40 = _mm512_add_epi64(D2_40,carry);
	D2_40 = _mm512_sub_epi64(D2_40,borrow);
	borrow  = _mm512_srli_epi64(D2_40,52)&un;
	D2_40 = _mm512_and_si512(D2_40,mask52);*/







	
	//borrow  = _mm512_srli_epi64(out_44,52)&un;
	//out_44 = _mm512_and_si512(out_44,mask52);
	
	
	

	
	_mm512_store_epi64(out+0,D0_0);
	_mm512_store_epi64(out+1,D0_1);
	_mm512_store_epi64(out+2,D0_2);
	_mm512_store_epi64(out+3,D0_3);
	_mm512_store_epi64(out+4,D0_4);
	_mm512_store_epi64(out+5,D0_5);
	_mm512_store_epi64(out+6,D0_6);
	_mm512_store_epi64(out+7,D0_7);
	_mm512_store_epi64(out+8,D0_8);
	_mm512_store_epi64(out+9,D0_9);
	_mm512_store_epi64(out+10,D0_10);
	_mm512_store_epi64(out+11,D0_11);
	_mm512_store_epi64(out+12,D0_12);
	_mm512_store_epi64(out+13,D0_13);
	_mm512_store_epi64(out+14,D0_14);
	_mm512_store_epi64(out+15,D0_15);
	_mm512_store_epi64(out+16,D0_16);
	_mm512_store_epi64(out+17,D0_17);
	_mm512_store_epi64(out+18,D0_18);
	_mm512_store_epi64(out+19,D0_19);
	_mm512_store_epi64(out+20,D0_20);
	_mm512_store_epi64(out+21,D0_21);
	_mm512_store_epi64(out+22,D0_22);
	_mm512_store_epi64(out+23,D0_23);
	_mm512_store_epi64(out+24,D0_24);
	_mm512_store_epi64(out+25,D0_25);
	_mm512_store_epi64(out+26,D0_26);
	_mm512_store_epi64(out+27,D0_27);
	_mm512_store_epi64(out+28,D0_28);
	_mm512_store_epi64(out+29,D0_29);
	_mm512_store_epi64(out+30,D0_30);
	_mm512_store_epi64(out+31,D0_31);
	_mm512_store_epi64(out+32,D0_32);
	_mm512_store_epi64(out+33,D0_33);
	_mm512_store_epi64(out+34,D0_34);
	_mm512_store_epi64(out+35,D0_35);
	_mm512_store_epi64(out+36,D0_36);
	_mm512_store_epi64(out+37,D0_37);
	_mm512_store_epi64(out+38,D0_38);
	_mm512_store_epi64(out+39,D0_39);
	_mm512_store_epi64(out+40,D1_0);
	_mm512_store_epi64(out+41,D1_1);
	_mm512_store_epi64(out+42,D1_2);
	_mm512_store_epi64(out+43,D1_3);
	_mm512_store_epi64(out+44,D1_4);
	_mm512_store_epi64(out+45,D1_5);
	_mm512_store_epi64(out+46,D1_6);
	_mm512_store_epi64(out+47,D1_7);
	_mm512_store_epi64(out+48,D1_8);
	_mm512_store_epi64(out+49,D1_9);
	_mm512_store_epi64(out+50,D1_10);
	_mm512_store_epi64(out+51,D1_11);
	_mm512_store_epi64(out+52,D1_12);
	_mm512_store_epi64(out+53,D1_13);
	_mm512_store_epi64(out+54,D1_14);
	_mm512_store_epi64(out+55,D1_15);
	_mm512_store_epi64(out+56,D1_16);
	_mm512_store_epi64(out+57,D1_17);
	_mm512_store_epi64(out+58,D1_18);
	_mm512_store_epi64(out+59,D1_19);
	_mm512_store_epi64(out+60,D1_20);
	_mm512_store_epi64(out+61,D1_21);
	_mm512_store_epi64(out+62,D1_22);
	_mm512_store_epi64(out+63,D1_23);
	_mm512_store_epi64(out+64,D1_24);
	_mm512_store_epi64(out+65,D1_25);
	_mm512_store_epi64(out+66,D1_26);
	_mm512_store_epi64(out+67,D1_27);
	_mm512_store_epi64(out+68,D1_28);
	_mm512_store_epi64(out+69,D1_29);
	_mm512_store_epi64(out+70,D1_30);
	_mm512_store_epi64(out+71,D1_31);
	_mm512_store_epi64(out+72,D1_32);
	_mm512_store_epi64(out+73,D1_33);
	_mm512_store_epi64(out+74,D1_34);
	_mm512_store_epi64(out+75,D1_35);
	_mm512_store_epi64(out+76,D1_36);
	_mm512_store_epi64(out+77,D1_37);
	_mm512_store_epi64(out+78,D1_38);
	_mm512_store_epi64(out+79,D1_39);//*/





	/*_mm512_store_epi64(out+80,D1_40);
	_mm512_store_epi64(out+81,D1_41);
	_mm512_store_epi64(out+82,D1_42);
	_mm512_store_epi64(out+83,D1_43);
	_mm512_store_epi64(out+84,D1_44);
	_mm512_store_epi64(out+85,D1_45);
	_mm512_store_epi64(out+86,D1_46);
	_mm512_store_epi64(out+87,D1_47);
	_mm512_store_epi64(out+88,D1_48);
	_mm512_store_epi64(out+89,D1_49);
	_mm512_store_epi64(out+90,D1_50);
	_mm512_store_epi64(out+91,D1_51);
	_mm512_store_epi64(out+92,D1_52);
	_mm512_store_epi64(out+93,D1_53);
	_mm512_store_epi64(out+94,D1_54);
	_mm512_store_epi64(out+95,D1_55);
	_mm512_store_epi64(out+96,D1_56);
	_mm512_store_epi64(out+97,D1_57);
	_mm512_store_epi64(out+98,D1_58);
	_mm512_store_epi64(out+99,D1_59);
	_mm512_store_epi64(out+100,D1_60);
	_mm512_store_epi64(out+101,D1_61);
	_mm512_store_epi64(out+102,D1_62);
	_mm512_store_epi64(out+103,D1_63);
	_mm512_store_epi64(out+104,D1_64);
	_mm512_store_epi64(out+105,D1_65);
	_mm512_store_epi64(out+106,D1_66);
	_mm512_store_epi64(out+107,D1_67);
	_mm512_store_epi64(out+108,D1_68);
	_mm512_store_epi64(out+109,D1_69);
	_mm512_store_epi64(out+110,D1_70);
	_mm512_store_epi64(out+111,D1_71);
	_mm512_store_epi64(out+112,D1_72);
	_mm512_store_epi64(out+113,D1_73);
	_mm512_store_epi64(out+114,D1_74);
	_mm512_store_epi64(out+115,D1_75);
	_mm512_store_epi64(out+116,D1_76);
	_mm512_store_epi64(out+117,D1_77);
	_mm512_store_epi64(out+118,D1_78);
	_mm512_store_epi64(out+119,D1_79);
	_mm512_store_epi64(out+120,D2_40);
	_mm512_store_epi64(out+121,D2_41);
	_mm512_store_epi64(out+122,D2_42);
	_mm512_store_epi64(out+123,D2_43);
	_mm512_store_epi64(out+124,D2_44);
	_mm512_store_epi64(out+125,D2_45);
	_mm512_store_epi64(out+126,D2_46);
	_mm512_store_epi64(out+127,D2_47);
	_mm512_store_epi64(out+128,D2_48);
	_mm512_store_epi64(out+129,D2_49);
	_mm512_store_epi64(out+130,D2_50);
	_mm512_store_epi64(out+131,D2_51);
	_mm512_store_epi64(out+132,D2_52);
	_mm512_store_epi64(out+133,D2_53);
	_mm512_store_epi64(out+134,D2_54);
	_mm512_store_epi64(out+135,D2_55);
	_mm512_store_epi64(out+136,D2_56);
	_mm512_store_epi64(out+137,D2_57);
	_mm512_store_epi64(out+138,D2_58);
	_mm512_store_epi64(out+139,D2_59);
	_mm512_store_epi64(out+140,D2_60);
	_mm512_store_epi64(out+141,D2_61);
	_mm512_store_epi64(out+142,D2_62);
	_mm512_store_epi64(out+143,D2_63);
	_mm512_store_epi64(out+144,D2_64);
	_mm512_store_epi64(out+145,D2_65);
	_mm512_store_epi64(out+146,D2_66);
	_mm512_store_epi64(out+147,D2_67);
	_mm512_store_epi64(out+148,D2_68);
	_mm512_store_epi64(out+149,D2_69);
	_mm512_store_epi64(out+150,D2_70);
	_mm512_store_epi64(out+151,D2_71);
	_mm512_store_epi64(out+152,D2_72);
	_mm512_store_epi64(out+153,D2_73);
	_mm512_store_epi64(out+154,D2_74);
	_mm512_store_epi64(out+155,D2_75);
	_mm512_store_epi64(out+156,D2_76);
	_mm512_store_epi64(out+157,D2_77);
	_mm512_store_epi64(out+158,D2_78);
	_mm512_store_epi64(out+159,D2_79);//*/

	/*
	unsigned long int a64_full[8][NB_COEFF64], b64_full[8][NB_COEFF64], res64_full[8][NB_COEFF64*2], res_gmp_full[NB_COEFF64*2];
	fcontract_8_512_4154KK_res(res64_full, out);
	//for(int i=0;i<8;i++)
	//		displayVect(res64_full[i],"res64[i]    ",NB_COEFF64*2);

	fcontract_8_512_4154KK(a64_full, a512);
	
	fcontract_8_512_4154KK(b64_full, b512);
	
	
	
	for(int i=0;i<8;i++)
	{

		mpz_import(A, NB_COEFF64, -1, sizeof(b64[0][0]) ,0,0, a64_full[i]);

		mpz_import(B, NB_COEFF64, -1, sizeof(b64[0][0]) ,0,0, b64_full[i]);
		
		gmp_printf("A  : 0x%ZX\n", A);

		displayVect(a64_full[i],"a64",65);
		printf("\n\n");
		
		gmp_printf("B  : 0x%ZX\n", B);
		displayVect(b64_full[i],"b64",65);
		printf("\n\n");
		
		
	
	
		mpz_mul(C,A,B);
		mpz_export(res_gmp_full, &countp, -1, sizeof(b64[0][0]) ,0,0, C);
		displayVect(res_gmp_full, "res_gmp     ",NB_COEFF64*2);
		displayVect(res64_full[i],"res64[i]    ",NB_COEFF64*2);
		
		
		printf("xor = ");
		for(int j=0;j<NB_COEFF64*2;j++){
			printf("%16.16lX ",res64_full[i][NB_COEFF64*2-1-j]^res_gmp_full[NB_COEFF64*2-1-j]);
		}
		printf("\n");

	//}
	//printf("\n");
	
	//for(int i=0;i<8;i++){//
		for(int j=0;j<NB_COEFF64*2;j++)
			if(res64_full[i][j]^res_gmp_full[j]) flag++;
		flag?counter++,flag=0:counter,flag=0;
		printf("\n");
	}
	if(counter) printf("%d erreurs !\nToo bad !!!!!!!!!!!!!!!!!!!\n\n",counter),counter=0;
	else printf("Victory a*b !!!!!!!!!!!!!!!!!!!\n\n");
	counter=0;

	mpz_clears (A, B, C, NULL);

	//getchar();//*/
	



}
